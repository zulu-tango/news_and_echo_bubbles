{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7edd8cd9",
   "metadata": {},
   "source": [
    "# facebook/bart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2db164ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "894b985bb84f46a4977c5bcf369407d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5723d11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "716b1d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "brainded_left = pd.read_csv('/Users/renato/code/zulu-tango/news_and_echo_bubbles/braindedleft.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2f48d325-0c09-4aa1-a5de-e1f11f91aa33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>link</th>\n",
       "      <th>pdate</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>keywords</th>\n",
       "      <th>tags</th>\n",
       "      <th>compound</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://kindest.com/442355-defend-democracy-to...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Defend Democracy Today: Support Fearless, Insi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>While the election has come and gone, the figh...</td>\n",
       "      <td>['reporting', 'come', 'today', 'access', 'chec...</td>\n",
       "      <td>set()</td>\n",
       "      <td>0.8612</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.165589</td>\n",
       "      <td>0.539782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://www.alternet.org/2021/03/dan-crenshaw/</td>\n",
       "      <td>2021-03-22 10:17:36+00:00</td>\n",
       "      <td>Republican Dan Crenshaw goes down in flames du...</td>\n",
       "      <td>['Sarah K. Burris', 'Raw Story']</td>\n",
       "      <td>MSNBC host Mehdi Hasan went after Rep. Dan Cre...</td>\n",
       "      <td>['come', 'didnt', 'going', 'fox', 'biden', 'cr...</td>\n",
       "      <td>{'Religious right'}</td>\n",
       "      <td>0.6474</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.069</td>\n",
       "      <td>-0.034989</td>\n",
       "      <td>0.411162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://www.alternet.org/2021/03/rep-dan-crens...</td>\n",
       "      <td>2021-03-09 13:32:36+00:00</td>\n",
       "      <td>Rep. Dan Crenshaw purchased stock during pande...</td>\n",
       "      <td>['Meaghan Ellis']</td>\n",
       "      <td>Rep. Dan Crenshaw's (R-Texas) stock purchase h...</td>\n",
       "      <td>['purchased', 'transactions', 'law', 'pandemic...</td>\n",
       "      <td>{'Religious right'}</td>\n",
       "      <td>-0.8949</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.011441</td>\n",
       "      <td>0.323766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>https://www.alternet.org/2020/11/dan-crenshaw/</td>\n",
       "      <td>2020-11-23 12:14:56+00:00</td>\n",
       "      <td>Sen. Ed Markey applauded for silent dismissal ...</td>\n",
       "      <td>['Walter Einenkel', 'Daily Kos']</td>\n",
       "      <td>Sen. Ed Markey is the Massachusetts Democrat w...</td>\n",
       "      <td>['district', 'lame', 'markey', 'office', 'rep'...</td>\n",
       "      <td>{'Religious right'}</td>\n",
       "      <td>0.9289</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.081250</td>\n",
       "      <td>0.439912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://www.alternet.org/2019/05/rep-dan-crens...</td>\n",
       "      <td>2019-05-06 17:40:27+00:00</td>\n",
       "      <td>Rep. Dan Crenshaw gets cornered on The View fo...</td>\n",
       "      <td>['Travis Gettys', 'Raw Story']</td>\n",
       "      <td>Rep. Dan Crenshaw (R-TX) appeared on “The View...</td>\n",
       "      <td>['words', 'view', 'offering', 'think', 'omar',...</td>\n",
       "      <td>{'Religious right'}</td>\n",
       "      <td>-0.4810</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.045094</td>\n",
       "      <td>0.453717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2406</th>\n",
       "      <td>2406</td>\n",
       "      <td>https://theintercept.com/document/2020/11/30/a...</td>\n",
       "      <td>2020-04-20 17:39:46+00:00</td>\n",
       "      <td>Conversations With ‘The Nation’: The Rev. Dr. ...</td>\n",
       "      <td>['The Nation', 'Alexandra Brodsky', 'John Nich...</td>\n",
       "      <td>“If you had only 48 hours of breath left, what...</td>\n",
       "      <td>['reverend', 'dr', 'conversations', 'united', ...</td>\n",
       "      <td>set()</td>\n",
       "      <td>0.7131</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.090121</td>\n",
       "      <td>0.536848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2407</th>\n",
       "      <td>2407</td>\n",
       "      <td>https://theintercept.com/document/2020/11/23/n...</td>\n",
       "      <td>2020-04-13 14:06:04+00:00</td>\n",
       "      <td>After Bernie: A Live Debate</td>\n",
       "      <td>['The Nation', 'Alexandra Brodsky', 'John Nich...</td>\n",
       "      <td>Bernie’s out: Senator Sanders suspended his ca...</td>\n",
       "      <td>['shahid', 'suspended', 'waleed', 'standardbea...</td>\n",
       "      <td>set()</td>\n",
       "      <td>0.4019</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.295833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2408</th>\n",
       "      <td>2408</td>\n",
       "      <td>https://theintercept.com/2021/03/16/texas-priv...</td>\n",
       "      <td>2020-02-19 16:58:58+00:00</td>\n",
       "      <td>Sanders or Warren: Time to Choose?</td>\n",
       "      <td>['The Nation', 'Alexandra Brodsky', 'John Nich...</td>\n",
       "      <td>Elizabeth Warren or Bernie Sanders? Plenty of ...</td>\n",
       "      <td>['school', 'watch', 'progressives', 'sanders',...</td>\n",
       "      <td>set()</td>\n",
       "      <td>0.5499</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.096</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2409</th>\n",
       "      <td>2409</td>\n",
       "      <td>https://theintercept.com/2021/03/14/child-migr...</td>\n",
       "      <td>2019-09-04 11:00:31+00:00</td>\n",
       "      <td>The White Power Movement From Reagan to Trump</td>\n",
       "      <td>['Jon Wiener', 'Alexandra Brodsky', 'John Nich...</td>\n",
       "      <td>Subscribe to The Nation Subscribe now for as l...</td>\n",
       "      <td>['war', 'women', 'violence', 'reagan', 'white'...</td>\n",
       "      <td>set()</td>\n",
       "      <td>-0.9554</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.083106</td>\n",
       "      <td>0.382314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2410</th>\n",
       "      <td>2410</td>\n",
       "      <td>https://theintercept.com/2021/03/14/missouri-p...</td>\n",
       "      <td>2019-07-03 18:59:13+00:00</td>\n",
       "      <td>VIDEO: A General Strike Is Possible, but We Ha...</td>\n",
       "      <td>['The Nation', 'Alexandra Brodsky', 'John Nich...</td>\n",
       "      <td>On May 9, Nation strikes correspondent Jane Mc...</td>\n",
       "      <td>['work', 'speech', 'centenary', 'address', 'ge...</td>\n",
       "      <td>set()</td>\n",
       "      <td>-0.8689</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.053864</td>\n",
       "      <td>0.549545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2411 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                               link  \\\n",
       "0              0  https://kindest.com/442355-defend-democracy-to...   \n",
       "1              1     https://www.alternet.org/2021/03/dan-crenshaw/   \n",
       "2              2  https://www.alternet.org/2021/03/rep-dan-crens...   \n",
       "3              3     https://www.alternet.org/2020/11/dan-crenshaw/   \n",
       "4              4  https://www.alternet.org/2019/05/rep-dan-crens...   \n",
       "...          ...                                                ...   \n",
       "2406        2406  https://theintercept.com/document/2020/11/30/a...   \n",
       "2407        2407  https://theintercept.com/document/2020/11/23/n...   \n",
       "2408        2408  https://theintercept.com/2021/03/16/texas-priv...   \n",
       "2409        2409  https://theintercept.com/2021/03/14/child-migr...   \n",
       "2410        2410  https://theintercept.com/2021/03/14/missouri-p...   \n",
       "\n",
       "                          pdate  \\\n",
       "0                           NaN   \n",
       "1     2021-03-22 10:17:36+00:00   \n",
       "2     2021-03-09 13:32:36+00:00   \n",
       "3     2020-11-23 12:14:56+00:00   \n",
       "4     2019-05-06 17:40:27+00:00   \n",
       "...                         ...   \n",
       "2406  2020-04-20 17:39:46+00:00   \n",
       "2407  2020-04-13 14:06:04+00:00   \n",
       "2408  2020-02-19 16:58:58+00:00   \n",
       "2409  2019-09-04 11:00:31+00:00   \n",
       "2410  2019-07-03 18:59:13+00:00   \n",
       "\n",
       "                                                  title  \\\n",
       "0     Defend Democracy Today: Support Fearless, Insi...   \n",
       "1     Republican Dan Crenshaw goes down in flames du...   \n",
       "2     Rep. Dan Crenshaw purchased stock during pande...   \n",
       "3     Sen. Ed Markey applauded for silent dismissal ...   \n",
       "4     Rep. Dan Crenshaw gets cornered on The View fo...   \n",
       "...                                                 ...   \n",
       "2406  Conversations With ‘The Nation’: The Rev. Dr. ...   \n",
       "2407                        After Bernie: A Live Debate   \n",
       "2408                 Sanders or Warren: Time to Choose?   \n",
       "2409      The White Power Movement From Reagan to Trump   \n",
       "2410  VIDEO: A General Strike Is Possible, but We Ha...   \n",
       "\n",
       "                                                 author  \\\n",
       "0                                                    []   \n",
       "1                      ['Sarah K. Burris', 'Raw Story']   \n",
       "2                                     ['Meaghan Ellis']   \n",
       "3                      ['Walter Einenkel', 'Daily Kos']   \n",
       "4                        ['Travis Gettys', 'Raw Story']   \n",
       "...                                                 ...   \n",
       "2406  ['The Nation', 'Alexandra Brodsky', 'John Nich...   \n",
       "2407  ['The Nation', 'Alexandra Brodsky', 'John Nich...   \n",
       "2408  ['The Nation', 'Alexandra Brodsky', 'John Nich...   \n",
       "2409  ['Jon Wiener', 'Alexandra Brodsky', 'John Nich...   \n",
       "2410  ['The Nation', 'Alexandra Brodsky', 'John Nich...   \n",
       "\n",
       "                                                   text  \\\n",
       "0     While the election has come and gone, the figh...   \n",
       "1     MSNBC host Mehdi Hasan went after Rep. Dan Cre...   \n",
       "2     Rep. Dan Crenshaw's (R-Texas) stock purchase h...   \n",
       "3     Sen. Ed Markey is the Massachusetts Democrat w...   \n",
       "4     Rep. Dan Crenshaw (R-TX) appeared on “The View...   \n",
       "...                                                 ...   \n",
       "2406  “If you had only 48 hours of breath left, what...   \n",
       "2407  Bernie’s out: Senator Sanders suspended his ca...   \n",
       "2408  Elizabeth Warren or Bernie Sanders? Plenty of ...   \n",
       "2409  Subscribe to The Nation Subscribe now for as l...   \n",
       "2410  On May 9, Nation strikes correspondent Jane Mc...   \n",
       "\n",
       "                                               keywords                 tags  \\\n",
       "0     ['reporting', 'come', 'today', 'access', 'chec...                set()   \n",
       "1     ['come', 'didnt', 'going', 'fox', 'biden', 'cr...  {'Religious right'}   \n",
       "2     ['purchased', 'transactions', 'law', 'pandemic...  {'Religious right'}   \n",
       "3     ['district', 'lame', 'markey', 'office', 'rep'...  {'Religious right'}   \n",
       "4     ['words', 'view', 'offering', 'think', 'omar',...  {'Religious right'}   \n",
       "...                                                 ...                  ...   \n",
       "2406  ['reverend', 'dr', 'conversations', 'united', ...                set()   \n",
       "2407  ['shahid', 'suspended', 'waleed', 'standardbea...                set()   \n",
       "2408  ['school', 'watch', 'progressives', 'sanders',...                set()   \n",
       "2409  ['war', 'women', 'violence', 'reagan', 'white'...                set()   \n",
       "2410  ['work', 'speech', 'centenary', 'address', 'ge...                set()   \n",
       "\n",
       "      compound    neg    neu    pos  polarity  subjectivity  \n",
       "0       0.8612  0.063  0.819  0.118  0.165589      0.539782  \n",
       "1       0.6474  0.055  0.876  0.069 -0.034989      0.411162  \n",
       "2      -0.8949  0.082  0.860  0.058  0.011441      0.323766  \n",
       "3       0.9289  0.071  0.811  0.118  0.081250      0.439912  \n",
       "4      -0.4810  0.077  0.848  0.075  0.045094      0.453717  \n",
       "...        ...    ...    ...    ...       ...           ...  \n",
       "2406    0.7131  0.089  0.807  0.104  0.090121      0.536848  \n",
       "2407    0.4019  0.077  0.810  0.113  0.037500      0.295833  \n",
       "2408    0.5499  0.051  0.853  0.096  1.000000      0.300000  \n",
       "2409   -0.9554  0.077  0.842  0.081  0.083106      0.382314  \n",
       "2410   -0.8689  0.133  0.831  0.036  0.053864      0.549545  \n",
       "\n",
       "[2411 rows x 14 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brainded_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a34c8a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "#model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "\n",
    "\n",
    "#input_ids = tokenizer.encode(text1, return_tensors='pt')\n",
    "#summary_ids = model.generate(input_ids, max_length=150, num_return_sequences=1, early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de91ae94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f63c62ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_sum = pipe(text1,max_length=229, min_length=30, do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51fa94b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Rep. Dan Crenshaw (R-TX) twisted data about border crossings to score points on Fox News. MSNBC host Mehdi Hasan explained that there is an influx of migrants coming over the border, the problem is that the numbers don't reflect that.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_sum[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f918970",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "091f3602",
   "metadata": {},
   "source": [
    "# sshleifer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2f29768",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2 = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "622e4d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" MSNBC host Mehdi Hasan went after Rep. Dan Crenshaw (R-TX) on Twitter this week after a Fox News appearance in which he twisted data about border crossings to score points on Fox News . Hasan explained that there has been an influx of migrants over the past nine months from President Donald Trump's administration into the Biden administration .\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe2(text1)[0]['summary_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bbefde",
   "metadata": {},
   "source": [
    "# philschmid/bart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ae02fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe3 = pipeline(\"summarization\", model=\"philschmid/bart-large-cnn-samsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ac262f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': \"Mehdi Hasan went after Rep. Dan Crenshaw (R-TX) on Twitter this week after a Fox News appearance in which he twisted data about border crossings to score points on Fox News. Hasan explained that there has been an influx of migrants over the past nine months from President Donald Trump's administration into the Biden administration. Crenshaw denied he said that Biden wasn't going to deport people.\"}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe3(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb9b8c56-f39f-4424-8641-745df7446dd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>link</th>\n",
       "      <th>pdate</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>keywords</th>\n",
       "      <th>tags</th>\n",
       "      <th>compound</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://kindest.com/442355-defend-democracy-to...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Defend Democracy Today: Support Fearless, Insi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>While the election has come and gone, the figh...</td>\n",
       "      <td>['reporting', 'come', 'today', 'access', 'chec...</td>\n",
       "      <td>set()</td>\n",
       "      <td>0.8612</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.165589</td>\n",
       "      <td>0.539782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://www.alternet.org/2021/03/dan-crenshaw/</td>\n",
       "      <td>2021-03-22 10:17:36+00:00</td>\n",
       "      <td>Republican Dan Crenshaw goes down in flames du...</td>\n",
       "      <td>['Sarah K. Burris', 'Raw Story']</td>\n",
       "      <td>MSNBC host Mehdi Hasan went after Rep. Dan Cre...</td>\n",
       "      <td>['come', 'didnt', 'going', 'fox', 'biden', 'cr...</td>\n",
       "      <td>{'Religious right'}</td>\n",
       "      <td>0.6474</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.069</td>\n",
       "      <td>-0.034989</td>\n",
       "      <td>0.411162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               link  \\\n",
       "0           0  https://kindest.com/442355-defend-democracy-to...   \n",
       "1           1     https://www.alternet.org/2021/03/dan-crenshaw/   \n",
       "\n",
       "                       pdate  \\\n",
       "0                        NaN   \n",
       "1  2021-03-22 10:17:36+00:00   \n",
       "\n",
       "                                               title  \\\n",
       "0  Defend Democracy Today: Support Fearless, Insi...   \n",
       "1  Republican Dan Crenshaw goes down in flames du...   \n",
       "\n",
       "                             author  \\\n",
       "0                                []   \n",
       "1  ['Sarah K. Burris', 'Raw Story']   \n",
       "\n",
       "                                                text  \\\n",
       "0  While the election has come and gone, the figh...   \n",
       "1  MSNBC host Mehdi Hasan went after Rep. Dan Cre...   \n",
       "\n",
       "                                            keywords                 tags  \\\n",
       "0  ['reporting', 'come', 'today', 'access', 'chec...                set()   \n",
       "1  ['come', 'didnt', 'going', 'fox', 'biden', 'cr...  {'Religious right'}   \n",
       "\n",
       "   compound    neg    neu    pos  polarity  subjectivity  \n",
       "0    0.8612  0.063  0.819  0.118  0.165589      0.539782  \n",
       "1    0.6474  0.055  0.876  0.069 -0.034989      0.411162  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brainded_left.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d384c7b5-0468-4940-b12a-008633815f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2411"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brainded_left[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "825da6e0-2b3e-467b-9221-5a0d201be8d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list( range(0,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "323c9436-17d0-4396-989b-24d2a18bdf07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2411"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brainded_left[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8419594e-e6be-4531-a4b7-ffbe13c1d3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipeface = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "def facebookbart_summ(dataframe):\n",
    "    alltexsumm = []\n",
    "    for i in range(0, (len(dataframe[\"text\"])+1)):  \n",
    "        text_sum = pipeface(dataframe[\"text\"][i],min_length=10, max_length=30)\n",
    "        alltexsumm.append(text_sum)\n",
    "    return alltexsumm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fdbd69-f1d5-4366-9ff4-781809809185",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "981c8a10-a252-4b7d-9c5a-f09713629d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#facebookbart_summ(brainded_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d1f037-bd77-4908-abb2-c7bb4d0b1a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.generate(input_ids, max_length=100, num_return_sequences=1, early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca0a87c-6bbf-4be3-ac54-94675f662d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d44a1d2-c70d-4a9a-8682-3685b48b0d05",
   "metadata": {},
   "source": [
    "# facebook summ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "18a472e6-8ffa-419a-a824-54e69a96bd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def facebookbart_summ(text):\n",
    "    from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "    \n",
    "    # Charger le tokenizer et le modèle\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "    \n",
    "    # Encoder le texte\n",
    "    input_ids = tokenizer.encode(text, return_tensors='pt')\n",
    "    \n",
    "    # Générer le résumé pour le texte donné\n",
    "    output = model.generate(input_ids, min_length=15, max_length=100, num_return_sequences=1, early_stopping=True)\n",
    "    \n",
    "    # Décoder la sortie pour obtenir le résumé\n",
    "    decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    \n",
    "    return decoded_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9cd4062c-0717-480d-b061-d5ad00c0b68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a2494c7c-2257-48a5-b263-403817a7d4de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2009"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brainded_left[\"text\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5f0c8e2c-f903-4014-9336-b1c4fe656d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16 s, sys: 3.09 s, total: 19.1 s\n",
      "Wall time: 19.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"MSNBC host Mehdi Hasan went after Rep. Dan Crenshaw (R-TX) on Twitter this week after a Fox News appearance in which he twisted data about border crossings to score points. Hasan explained that the problem is that there has been an influx of migrants over the past nine months from President Donald Trump's administration into the Biden administration.\""
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "facebookbart_summ(brainded_left[\"text\"][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517bddd4-277a-49c7-a758-3143df65a90b",
   "metadata": {},
   "source": [
    "# philschmid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "17c7ad26-7a05-46e9-98d2-40de02510246",
   "metadata": {},
   "outputs": [],
   "source": [
    "def philschmid_summ(text):\n",
    "    from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "    \n",
    "    # Load the tokenizer and model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"philschmid/bart-large-cnn-samsum\")\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\"philschmid/bart-large-cnn-samsum\")\n",
    "    \n",
    "    # Encode the text\n",
    "    input_ids = tokenizer.encode(text, return_tensors='pt', max_length=1024, truncation=True)\n",
    "    \n",
    "    # Generate summary for the text\n",
    "    output = model.generate(input_ids, max_length=100, num_return_sequences=1, early_stopping=True)\n",
    "    \n",
    "    # Decode the output to get the summary\n",
    "    decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    \n",
    "    return decoded_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a525b092-8ed0-448e-b9a2-c35010cf426c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.2 s, sys: 4.67 s, total: 20.9 s\n",
      "Wall time: 18.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"MSNBC host Mehdi Hasan went after Rep. Dan Crenshaw (R-TX) on Twitter this week after a Fox News appearance in which he twisted data about border crossings to score points on Fox News. Hasan explained that there has been an influx of migrants over the past nine months from President Donald Trump's administration into the Biden administration. Crenshaw denied he said that Biden wasn't going to deport people.\""
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "philschmid_summ(brainded_left[\"text\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306e8567-6c1c-4ab9-83a9-4bf0ad25a731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b543966-a649-46b2-a996-e76a9856d108",
   "metadata": {},
   "source": [
    "# sshleifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3fd50cfd-db10-4fcd-9632-1f775269e8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sshleifer_summarize(text):\n",
    "    from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "    \n",
    "    # Load the tokenizer and model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"sshleifer/distilbart-cnn-12-6\")\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\"sshleifer/distilbart-cnn-12-6\")\n",
    "    \n",
    "    # Encode the text\n",
    "    input_ids = tokenizer.encode(text, return_tensors='pt', max_length=1024, truncation=True)\n",
    "    \n",
    "    # Generate summary for the text\n",
    "    output = model.generate(input_ids, max_length=100, num_return_sequences=1, early_stopping=True)\n",
    "    \n",
    "    # Decode the output to get the summary\n",
    "    decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    \n",
    "    return decoded_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "087edc7c-81e4-486a-a8af-b529ad47ba3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.3 s, sys: 3.46 s, total: 14.7 s\n",
      "Wall time: 12.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" MSNBC host Mehdi Hasan went after Rep. Dan Crenshaw (R-TX) on Twitter this week after a Fox News appearance in which he twisted data about border crossings to score points on Fox News. Hasan explained that there has been an influx of migrants over the past nine months from President Donald Trump's administration into the Biden administration.\""
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "sshleifer_summarize(brainded_left[\"text\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a9c210bf-f50b-46bc-a44a-3663fcd7b874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The appointments \"confirm that Sen. Warren will be the most influential voice in the financial policy debate under the new administration,\" a former Democratic Senate aide says. The growing list of Biden personnel backed by Warren and other progressives illustrates the leftward shift underway in the Democratic Party\\'s approach to policymaking, which was also seen in the $1.9 trillion aid package.'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sshleifer_summarize(brainded_left[\"text\"][1220])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c667af-4514-427d-8f77-4c5018a45976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17380cd5-f284-407e-a8bd-e98597ab16c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca9cab8c-ba47-42f6-bb42-cdd74cbf4efb",
   "metadata": {},
   "source": [
    "# pegasus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "24cbef69-77b6-41dd-a2f3-3d43621f502d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pegasus_summarize(text):\n",
    "    from transformers import pipeline\n",
    "\n",
    "    pipe = pipeline(\"summarization\", model=\"google/pegasus-xsum\")\n",
    "    \n",
    "    return pipe(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "750e07a0-4e5c-49b9-83f6-18a015f93632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf10b28df75045bb883a1b514d43d25a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f234b94bcd074837b132e58f66ec754a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/259 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7eaf7fff3b44076a5c16589c63cd2b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/87.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "381ce10aa8754689b479dd9692e45438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/1.91M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4ae06c8e5af4d22b3b34080d20da254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/3.52M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fee43320fe7244138a8246f8bddd0981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.4 s, sys: 20.3 s, total: 44.7 s\n",
      "Wall time: 3min 25s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'A war of words has broken out between an MSNBC host and a Republican congressman over border security.'}]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pegasus_summarize(brainded_left[\"text\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6cffca9c-ab05-4cca-a889-4e54181aa232",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.5 s, sys: 9.73 s, total: 26.2 s\n",
      "Wall time: 31.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'A war of words has broken out between an MSNBC host and a Republican congressman over border security.'}]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pegasus_summarize(brainded_left[\"text\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16cfd73-2ca2-4cac-a61a-bea7618bfe6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d417ed55-ae1d-4f6e-88de-2b0a73a68d73",
   "metadata": {},
   "source": [
    "# knkarthick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ea677688-5369-4063-aaa0-716e1396f299",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knkarthick_summarize(text):\n",
    "    from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "    \n",
    "    # Load the tokenizer and model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"knkarthick/MEETING_SUMMARY\")\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\"knkarthick/MEETING_SUMMARY\")\n",
    "    \n",
    "    # Encode the text\n",
    "    input_ids = tokenizer.encode(text, return_tensors='pt', max_length=1024, truncation=True)\n",
    "    \n",
    "    # Generate summary for the text\n",
    "    output = model.generate(input_ids, max_length=200, num_return_sequences=1, early_stopping=True)\n",
    "    \n",
    "    # Decode the output to get the summary\n",
    "    decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    \n",
    "    return decoded_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ddb7f9dd-6e96-4fb0-a02f-dbaa4927e951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91cc6df9011d481f93c3554ee9b28c7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/337 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33433a68d1ae4035ab57a4811f2db51e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70daaf4fae1c4fa58e083e0b17b1f41e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d27a3643b7c54fa1baac2fed2d1d6daf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b95b5f3780fd410cbd1a2f3eb0039635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31345747c4c342d9acb28ae12e5851b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.59k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b946d2c3c39472ebb08e20e55201ec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'According to Mehdi Hasan, there has been an influx of migrants over the past nine months. According to Crenshaw, it happened overnight when President Biden rescinded the remain in Mexico policy.'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knkarthick_summarize(brainded_left[\"text\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f5792df3-9f1b-4022-8264-bde467df91f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.8 s, sys: 4.13 s, total: 18 s\n",
      "Wall time: 16.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'According to Mehdi Hasan, there has been an influx of migrants over the past nine months. According to Crenshaw, it happened overnight when President Biden rescinded the remain in Mexico policy.'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "knkarthick_summarize(brainded_left[\"text\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4af2b0-ad12-4f3f-9fbc-4877024ea6b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6362f8b8-fd24-488a-9b34-8e07e63a7f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef3392cb-b3df-4f4c-b770-dd6f9813477d",
   "metadata": {},
   "source": [
    "# pszemraj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c43e612f-c35f-47ef-bbb5-533f34584b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pszemraj_summary(text):\n",
    "    from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "    \n",
    "    # Load the tokenizer and model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"pszemraj/led-large-book-summary\")\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\"pszemraj/led-large-book-summary\")\n",
    "    \n",
    "    # Encode the text\n",
    "    input_ids = tokenizer.encode(text, return_tensors='pt', max_length=1024, truncation=True)\n",
    "    \n",
    "    # Generate summary for the text\n",
    "    output = model.generate(input_ids, max_length=200, num_return_sequences=1, early_stopping=True)\n",
    "    \n",
    "    # Decode the output to get the summary\n",
    "    decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    \n",
    "    return decoded_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "64e8420f-68ba-4c4c-be2c-b6c53211c340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bac023e17cef4bc1a609e03ef30ebc35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "386b2233a64b436bba0e9f941eb01bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24982ee823c5489e845491cda09a4093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1ae4e61faa44912a9168f4768f59bbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73333c19045a493b84f3a4e4b4ebef19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e46b0928f61412e81fa916ce1a74834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.44k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc9c0b029a694362b9aa6cba12ea236e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.84G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Mehdi Hasan mocks Rep. Dan Crenshaw (R-TX) on Twitter after a Fox News appearance in which he twisted data about border crossings to score points on Fox News. He then invites the congressman on his show to talk about the issue and avoid \"political nonsense.\" Hasan shows data from the CBP showing that there is an influx of migrants coming over the border, but the problem is that there has actually been an influx from President Donald Trump\\'s administration into the Biden administration. What became very clear is that Hasan came with the numbers and Crenshaw didn\\'t know them. The next big piece of information was that people are crossing the border again after being thrown out during the Trump administration.'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pszemraj_summary(brainded_left[\"text\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "09aafa62-06ae-4d08-94de-051101b0d216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.6 s, sys: 14.8 s, total: 55.4 s\n",
      "Wall time: 50.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Mehdi Hasan mocks Rep. Dan Crenshaw (R-TX) on Twitter after a Fox News appearance in which he twisted data about border crossings to score points on Fox News. He then invites the congressman on his show to talk about the issue and avoid \"political nonsense.\" Hasan shows data from the CBP showing that there is an influx of migrants coming over the border, but the problem is that there has actually been an influx from President Donald Trump\\'s administration into the Biden administration. What became very clear is that Hasan came with the numbers and Crenshaw didn\\'t know them. The next big piece of information was that people are crossing the border again after being thrown out during the Trump administration.'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "pszemraj_summary(brainded_left[\"text\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0da11f-9c78-41a3-8604-de4ecd60a22b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb393056-2cc6-4364-97a1-9c6487bdf5ad",
   "metadata": {},
   "source": [
    "# Falconsai =  good speed/ bad quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20af8cf-93f4-4bec-8086-9d9b2f7b61be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "46ecc56a-27be-481a-bf99-ccb60f1f7703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Falconsai_summarization(text):\n",
    "    from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "    \n",
    "    # Load the tokenizer and model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"Falconsai/medical_summarization\")\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\"Falconsai/medical_summarization\")\n",
    "    \n",
    "    # Encode the text\n",
    "    input_ids = tokenizer.encode(text, return_tensors='pt', max_length=1024, truncation=True)\n",
    "    \n",
    "    # Generate summary for the text\n",
    "    output = model.generate(input_ids, max_length=200, num_return_sequences=1, early_stopping=True)\n",
    "    \n",
    "    # Decode the output to get the summary\n",
    "    decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    \n",
    "    return decoded_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f0fe1afe-abbf-41e6-ab10-cb3fe85fbb91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00e8dcc4805a4d92ab1a0687d4f19d4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.37k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "613dabc7f007477b85043fdbfaab71ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24c21eb623ba403b98fa875dcacf6265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bb0232deb6a48f6926862bf988cdf2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2690507ef774c678354da0be81d7624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.47k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1480b18762c84a2ab2da4198f1aa0c0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ccfdab61bba448d9423e8739ce59ccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/renato/.pyenv/versions/3.10.6/envs/echo_news_bubbles/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:418: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"a huge influx of migrants has been reported over the past nine months from president Donald Trump's administration into the biden administration. a nonsense, however, continues to be a lie. a nonsense, a lie for the nonsense, is that there has been an influx of migrants coming over the border. a nonsense, a lie for the nonsense, is that there has been an influx of migrants coming over the border. a nonsense nonsense for the past nine months was that there was an influx of migrants coming over the border.\""
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Falconsai_summarization(brainded_left[\"text\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "896c72d4-6b2a-4460-8087-659632e3ad74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.75 s, sys: 198 ms, total: 2.94 s\n",
      "Wall time: 3.08 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"a huge influx of migrants has been reported over the past nine months from president Donald Trump's administration into the biden administration. a nonsense, however, continues to be a lie. a nonsense, a lie for the nonsense, is that there has been an influx of migrants coming over the border. a nonsense, a lie for the nonsense, is that there has been an influx of migrants coming over the border. a nonsense nonsense for the past nine months was that there was an influx of migrants coming over the border.\""
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "Falconsai_summarization(brainded_left[\"text\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a706a1-03d8-4477-af46-4741be273e66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16630ddf-eda0-41c1-89d6-677beb29a5b1",
   "metadata": {},
   "source": [
    "# lidiya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1b12da06-311e-493e-8c44-6bc5fe5773bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lidiya_summarize(text):\n",
    "    from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "    \n",
    "    # Load the tokenizer and model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"lidiya/bart-large-xsum-samsum\")\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\"lidiya/bart-large-xsum-samsum\")\n",
    "    \n",
    "    # Encode the text\n",
    "    input_ids = tokenizer.encode(text, return_tensors='pt', max_length=1024, truncation=True)\n",
    "    \n",
    "    # Generate summary for the text\n",
    "    output = model.generate(input_ids, max_length=200, num_return_sequences=1, early_stopping=True)\n",
    "    \n",
    "    # Decode the output to get the summary\n",
    "    decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    \n",
    "    return decoded_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8806f2d6-a4d5-48ce-a2c3-a1f08000eef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7056437e81164ba382f69a20c8e824f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/301 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "520ab9fd3f4b484ea5c23b68192c017d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.56k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f659c023769425eb613eef1deab4f49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "383c86fa69a94bc9a1f18d9995db61b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34564535b772475aa323f48c81c08842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0046e39f23354a7bb1e52e5b3c4a6d68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d316e1c078441979eba7eb9961c4c6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"MSNBC host Mehdi Hasan went after Rep. Dan Crenshaw over his Fox News interview in which he twisted data about border crossings to score points on Fox News. According to Hasan, there has been an influx of migrants coming over the border in the past nine months from President Donald Trump's administration into the Biden administration.\""
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lidiya_summarize(brainded_left[\"text\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "50b727ff-5521-40b7-8d23-b1108720e298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.5 s, sys: 6.75 s, total: 26.3 s\n",
      "Wall time: 26.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"MSNBC host Mehdi Hasan went after Rep. Dan Crenshaw over his Fox News interview in which he twisted data about border crossings to score points on Fox News. According to Hasan, there has been an influx of migrants coming over the border in the past nine months from President Donald Trump's administration into the Biden administration.\""
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "lidiya_summarize(brainded_left[\"text\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4553a18e-cef7-4a0a-a4b8-34c8ca405bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e27430ab-f8fc-4bc6-81ae-ec6dcfa8c6d2",
   "metadata": {},
   "source": [
    "# csebuetnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1aa94111-ac8f-43df-932c-96c1965d37fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csebuetnlp_summarize(text):\n",
    "    from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "    \n",
    "    # Load the tokenizer and model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"csebuetnlp/mT5_multilingual_XLSum\")\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\"csebuetnlp/mT5_multilingual_XLSum\")\n",
    "    \n",
    "    # Encode the text\n",
    "    input_ids = tokenizer.encode(text, return_tensors='pt', max_length=1024, truncation=True)\n",
    "    \n",
    "    # Generate summary for the text\n",
    "    output = model.generate(input_ids, max_length=200, num_return_sequences=1, early_stopping=True)\n",
    "    \n",
    "    # Decode the output to get the summary\n",
    "    decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    \n",
    "    return decoded_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e4e2f67b-bcf7-4150-93da-45320b29f0c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Couldn't instantiate the backend tokenizer from one of: \n(1) a `tokenizers` library serialization file, \n(2) a slow tokenizer instance to convert or \n(3) an equivalent slow tokenizer class to instantiate and convert. \nYou need to have sentencepiece installed to convert a slow tokenizer to a fast one.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[120], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcsebuetnlp_summarize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbrainded_left\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[119], line 5\u001b[0m, in \u001b[0;36mcsebuetnlp_summarize\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForSeq2SeqLM\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load the tokenizer and model\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsebuetnlp/mT5_multilingual_XLSum\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForSeq2SeqLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsebuetnlp/mT5_multilingual_XLSum\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Encode the text\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/echo_news_bubbles/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:768\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    765\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    766\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTokenizer class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtokenizer_class_candidate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist or is not currently imported.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    767\u001b[0m         )\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtokenizer_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;66;03m# Otherwise we have to be creative.\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;66;03m# if model is an encoder decoder, the encoder tokenizer class is used by default\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, EncoderDecoderConfig):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/echo_news_bubbles/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2024\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2021\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2022\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from cache at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresolved_vocab_files[file_id]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2024\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2025\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresolved_vocab_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2027\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_configuration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2028\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2029\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2030\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2031\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2032\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2033\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_is_local\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_local\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2034\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2035\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/echo_news_bubbles/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2256\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._from_pretrained\u001b[0;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2254\u001b[0m \u001b[38;5;66;03m# Instantiate the tokenizer.\u001b[39;00m\n\u001b[1;32m   2255\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2256\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2257\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m   2258\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m   2259\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to load vocabulary from file. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2260\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease check that the provided vocabulary is accessible and not corrupted.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2261\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/echo_news_bubbles/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:135\u001b[0m, in \u001b[0;36mT5TokenizerFast.__init__\u001b[0;34m(self, vocab_file, tokenizer_file, eos_token, unk_token, pad_token, extra_ids, additional_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m     extra_tokens \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<extra_id_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(extra_ids)]\n\u001b[1;32m    133\u001b[0m     additional_special_tokens \u001b[38;5;241m=\u001b[39m extra_tokens\n\u001b[0;32m--> 135\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvocab_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43meos_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meos_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43munk_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munk_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43madditional_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madditional_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_file \u001b[38;5;241m=\u001b[39m vocab_file\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extra_ids \u001b[38;5;241m=\u001b[39m extra_ids\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/echo_news_bubbles/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:120\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     fast_tokenizer \u001b[38;5;241m=\u001b[39m convert_slow_tokenizer(slow_tokenizer)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    121\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt instantiate the backend tokenizer from one of: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(1) a `tokenizers` library serialization file, \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(2) a slow tokenizer instance to convert or \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(3) an equivalent slow tokenizer class to instantiate and convert. \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    125\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need to have sentencepiece installed to convert a slow tokenizer to a fast one.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    126\u001b[0m     )\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenizer \u001b[38;5;241m=\u001b[39m fast_tokenizer\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m slow_tokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Couldn't instantiate the backend tokenizer from one of: \n(1) a `tokenizers` library serialization file, \n(2) a slow tokenizer instance to convert or \n(3) an equivalent slow tokenizer class to instantiate and convert. \nYou need to have sentencepiece installed to convert a slow tokenizer to a fast one."
     ]
    }
   ],
   "source": [
    "csebuetnlp_summarize(brainded_left[\"text\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0619f3-fe17-4c80-b7c4-be2c2d270713",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999cd17d-9bb9-44c8-bfb2-4d0d80ee3e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374ae8a5-a855-4333-b103-2510eb96f737",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
