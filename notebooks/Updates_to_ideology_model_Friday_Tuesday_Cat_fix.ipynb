{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc26e6f6-51c0-41e0-b1d6-fd78cf9a17b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-06 10:03:56.109891: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-06 10:03:56.189724: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-06 10:03:56.624890: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-06 10:03:56.624967: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-06 10:03:56.754251: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-06 10:03:56.969306: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-06 10:03:56.972364: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-06 10:03:58.653882: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers, losses\n",
    "from transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4ce87be-03e3-4e8d-ad6d-422704f4144b",
   "metadata": {},
   "outputs": [],
   "source": [
    "IM_MODEL_NAME = \"distilbert-base-uncased\"\n",
    "IM_BATCH_SIZE = 2\n",
    "IM_LEARNING_RATE = 3e-5\n",
    "IM_TOKEN_MAX_LEN = 50   ### currently set at 50 to speed up basic model training\n",
    "IM_TEST_SPLIT = 0.2\n",
    "IM_VALIDATION_SPLIT = 0.3   ### refers to split withing training data (not whole dataset)\n",
    "IM_EPOCHS = 5   ### currently set to 5 to speed up basic model training\n",
    "IM_PATIENCE = 2   ### currently set to 2 due to the low number of epochs (5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02dd374c-5a1b-4007-aa9e-439aea47bfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344bd4f5-a4d4-4a60-981b-eaedd20d59f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/connor/code/zulu-tango/news_and_echo_bubbles/raw_data/cleaned.csv', index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aa192c-4318-433b-9fcb-272932b3edc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop irrelevant columns and take a sample of 50 to test\n",
    "df = df.drop(columns = [\"link\", \"pdate\", \"title\", \"author\", \"text\", \"keywords\", \"tags\", \"compound\",\\\n",
    "                            \"neg\", \"neu\", \"pos\", \"polarity\", \"subjectivity\", \"time\", \"urls\"]).sample(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7584eec2-cb12-4bb2-9c92-f69df51ca1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ee0345-36cd-41d4-b7b5-906787a9b2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_list = [-1.89, -1.02, 1.6, 3.65, 2.8, -2.47, 1.39, 2.78, -3.65, -3.4, -3.48, 2.44, -4.07, -4.28, 4.71, 3.03, -0.68, 3.05, 0.06,\\\n",
    "                   4.86, 0.31, 2.18, -0.31, -3.47, -1.99, 1.81, -0.91, -1.17, 3.34, 1.41, -2.23, -3.17, 2.58, -3.13, -1.23, 0.56, 4.48, 3.48,\\\n",
    "                   -2.48, 3.37, -4.81, -1.84, -0.42, 4.94, 4.14, -1.59, 0.16, -4.29, -4.24, -4.23]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcb7129-0899-4690-b88c-07c18bccc0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(continuous_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48909374-e468-4b0c-b771-d2ff6756327e",
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_list = [-1, -2, 2, 0, 2, 0, 1, 0, 0, 2, 2, 1, 2, 0, -1, 2, -2, -2, -1, -2, 2, 1, 2, 1, 1, -1, -2, 2, 1, -2, -2, 2, -1, 0, 0,\\\n",
    "                 -1, -1, -2, 0, 1, -1, 1, 2, -1, 0, 1, 2, 2, 0, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dd3749-d1aa-4fd6-835f-ba0927f75f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(discrete_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6da7767-d1c2-4097-bee9-eb59e98f32d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"continuous_bias_score\"] = continuous_list\n",
    "df[\"discrete_bias_score\"] = discrete_list\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a5544c-c678-45bf-b525-9d77ad64cf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO DO: MAKE THE MODEL WORK USING THE \"CONTINUOUS_BIAS_SCORE\" AND \"DISCRETE_BIAS_SCORE\" COLUMNS\n",
    "### THE OUTPUT SHOULD STILL BE A PROBABILITY FROM 0 TO 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e32b0f-2a46-4c23-a47a-4fa720aad24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6642e7f-e950-4add-bc63-aad57d3ed957",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812aae04-48a7-4e91-8df4-83710012b8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_dict = {-2:[1,0,0,0,0],\n",
    "                -1:[0,1,0,0,0],\n",
    "                0:[0,0,1,0,0],\n",
    "                1:[0,0,0,1,0],\n",
    "                2:[0,0,0,0,1]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09a0b6a-f480-4218-8bd1-921058b1a415",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"one_hot_discrete\"] = df[\"discrete_bias_score\"].map(one_hot_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6792bca9-2928-482b-b663-29d08e67ed23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5d7d02-c20f-44a0-88e8-529c1895e2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NEW_get_X_and_y(df):\n",
    "    \"\"\"\n",
    "    Gets from our dataset: (i) the feature (i.e. X - the pre-processed text);\n",
    "    and (ii) the target (i.e. y - the ideology: left wing = 0 / right wing = 1).\n",
    "    These need to be converted into lists for use in our model.\n",
    "    \"\"\"\n",
    "\n",
    "    X = df[\"pre_process_text\"].tolist()\n",
    "    y = df[\"one_hot_discrete\"].tolist()\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1828ba4-56e0-4b50-b0bf-6a8096370a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = NEW_get_X_and_y(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4da6d2-262d-424b-996b-18ba06df6d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = instantiate_tokenizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7625b5-9e80-40cc-9cdb-f138a4a998b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = text_tokenizer(X, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98978ec2-ccf4-40f9-b789-d56a34e7eb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfdataset = tf_dataset_constructor(tokens, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b218ebf4-0643-4c8e-9436-ce33a911b422",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfdataset_train, tfdataset_val, tfdataset_test = train_test_split(X, tfdataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed436443-4976-4be5-afc3-40b7a37bc9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NEW_ideology_model(tfdataset_train,\n",
    "                   tfdataset_val,\n",
    "                   model_name = IM_MODEL_NAME,\n",
    "                   learning_rate = IM_LEARNING_RATE,\n",
    "                   batch_size = IM_BATCH_SIZE,\n",
    "                   epochs = IM_EPOCHS,\n",
    "                   patience = IM_PATIENCE):\n",
    "\n",
    "    \"\"\"\n",
    "    Set up an run a DistilBert model on our TensorFlow training dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    num_labels = 5  ################\n",
    "\n",
    "    # set up model\n",
    "    model = TFDistilBertForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "\n",
    "    # define loss function\n",
    "    loss = losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "    # define optimizer to be used to minimise loss\n",
    "    optimizer = optimizers.Adam(learning_rate)\n",
    "\n",
    "    # compile model\n",
    "    model.compile(optimizer = optimizer,\n",
    "                  loss = loss,\n",
    "                  metrics = \"accuracy\")\n",
    "\n",
    "    # fit model\n",
    "    model.fit(tfdataset_train,\n",
    "              batch_size = batch_size,\n",
    "              epochs = epochs,\n",
    "              validation_data = tfdataset_val,\n",
    "              callbacks = EarlyStopping(patience = patience, restore_best_weights = True))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be63709-cc47-4b2f-aeec-6b23a5c057cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NEW_ideology_model(tfdataset_train,\n",
    "                   tfdataset_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261753c0-07cd-4611-a5b3-ca0e9feeb5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = ideology_model_evaluator(model, tfdataset_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3d1313-cb16-4c79-867c-0c754fd01259",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probas = ideology_model_predictor(model,tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d1cad6-f3d5-4b29-8195-718e4ce54434",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6283cd-c2ed-4045-84d6-bac2b77f89d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba0b12b-d8ae-479c-9c7b-fe617646656a",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_class_list = []\n",
    "\n",
    "for row in range(len(pred_probas)):\n",
    "\n",
    "    conversion_dict = {0 : \"left\",\n",
    "                       1 : \"leans left\",\n",
    "                       2 : \"centre\",\n",
    "                       3 : \"leans right\",\n",
    "                       4 : \"right\"}\n",
    "\n",
    "    top_class_list.append(conversion_dict[np.argmax(pred_probas[row])])\n",
    "\n",
    "print(top_class_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd1d38f-9793-4e39-9c8a-d763f2d9f954",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f769f26f-485c-48a6-8028-ab655f21f9ae",
   "metadata": {},
   "source": [
    "## TESTING IN FULL!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbfb0809-11f8-4828-a599-dc8137f999b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/connor/code/zulu-tango/news_and_echo_bubbles/raw_data/cleaned.csv', index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "358e253d-1b6f-48b9-b2ff-b2d160a7fdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = [\"link\", \"classifier\", \"title\", \"author\", \"text\", \"keywords\", \"tags\", \"compound\",\\\n",
    "                            \"neg\", \"neu\", \"pos\", \"polarity\", \"subjectivity\", \"time\"]).sample(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a58151b-1106-4012-8b6b-080a16d6ffab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdate</th>\n",
       "      <th>urls</th>\n",
       "      <th>pre_process_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>2021-03-15</td>\n",
       "      <td>www.newyorker.com</td>\n",
       "      <td>let our journalists help you make sense of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>www.motherjones.com</td>\n",
       "      <td>let our journalists help you make sense of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1413</th>\n",
       "      <td>2021-03-22</td>\n",
       "      <td>www.huffpost.com</td>\n",
       "      <td>on march   a white gunman killed eight people ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>www.cnn.com</td>\n",
       "      <td>the populist wave in politics on both sides of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>2021-01-21</td>\n",
       "      <td>www.newyorker.com</td>\n",
       "      <td>let our journalists help you make sense of the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pdate                 urls  \\\n",
       "1071  2021-03-15    www.newyorker.com   \n",
       "1099  2021-03-02  www.motherjones.com   \n",
       "1413  2021-03-22     www.huffpost.com   \n",
       "410   2020-01-26          www.cnn.com   \n",
       "1061  2021-01-21    www.newyorker.com   \n",
       "\n",
       "                                       pre_process_text  \n",
       "1071  let our journalists help you make sense of the...  \n",
       "1099  let our journalists help you make sense of the...  \n",
       "1413  on march   a white gunman killed eight people ...  \n",
       "410   the populist wave in politics on both sides of...  \n",
       "1061  let our journalists help you make sense of the...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2cd0a0b-3e18-4cfa-afc2-b0285c5ea57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_list = [-1, -2, 2, 0, 2, 0, 1, 0, 0, 2, 2, 1, 2, 0, -1, 2, -2, -2, -1, -2, 2, 1, 2, 1, 1, -1, -2, 2, 1, -2, -2, 2, -1, 0, 0,\\\n",
    "                 -1, -1, -2, 0, 1, -1, 1, 2, -1, 0, 1, 2, 2, 0, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfaa263e-da8c-4a9f-813a-b38ec0b42c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdate</th>\n",
       "      <th>urls</th>\n",
       "      <th>pre_process_text</th>\n",
       "      <th>discrete_bias_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>2021-03-15</td>\n",
       "      <td>www.newyorker.com</td>\n",
       "      <td>let our journalists help you make sense of the...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>www.motherjones.com</td>\n",
       "      <td>let our journalists help you make sense of the...</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1413</th>\n",
       "      <td>2021-03-22</td>\n",
       "      <td>www.huffpost.com</td>\n",
       "      <td>on march   a white gunman killed eight people ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>www.cnn.com</td>\n",
       "      <td>the populist wave in politics on both sides of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>2021-01-21</td>\n",
       "      <td>www.newyorker.com</td>\n",
       "      <td>let our journalists help you make sense of the...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pdate                 urls  \\\n",
       "1071  2021-03-15    www.newyorker.com   \n",
       "1099  2021-03-02  www.motherjones.com   \n",
       "1413  2021-03-22     www.huffpost.com   \n",
       "410   2020-01-26          www.cnn.com   \n",
       "1061  2021-01-21    www.newyorker.com   \n",
       "\n",
       "                                       pre_process_text  discrete_bias_score  \n",
       "1071  let our journalists help you make sense of the...                   -1  \n",
       "1099  let our journalists help you make sense of the...                   -2  \n",
       "1413  on march   a white gunman killed eight people ...                    2  \n",
       "410   the populist wave in politics on both sides of...                    0  \n",
       "1061  let our journalists help you make sense of the...                    2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"discrete_bias_score\"] = discrete_list\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48de2727-70ac-4f06-8ded-d6dbc3387ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"5_step_classifier\"] = df[\"discrete_bias_score\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "924c50c6-17d6-4e3e-9dc7-c082376ee706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdate</th>\n",
       "      <th>urls</th>\n",
       "      <th>pre_process_text</th>\n",
       "      <th>discrete_bias_score</th>\n",
       "      <th>5_step_classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>2021-03-15</td>\n",
       "      <td>www.newyorker.com</td>\n",
       "      <td>let our journalists help you make sense of the...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>www.motherjones.com</td>\n",
       "      <td>let our journalists help you make sense of the...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1413</th>\n",
       "      <td>2021-03-22</td>\n",
       "      <td>www.huffpost.com</td>\n",
       "      <td>on march   a white gunman killed eight people ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>www.cnn.com</td>\n",
       "      <td>the populist wave in politics on both sides of...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>2021-01-21</td>\n",
       "      <td>www.newyorker.com</td>\n",
       "      <td>let our journalists help you make sense of the...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pdate                 urls  \\\n",
       "1071  2021-03-15    www.newyorker.com   \n",
       "1099  2021-03-02  www.motherjones.com   \n",
       "1413  2021-03-22     www.huffpost.com   \n",
       "410   2020-01-26          www.cnn.com   \n",
       "1061  2021-01-21    www.newyorker.com   \n",
       "\n",
       "                                       pre_process_text  discrete_bias_score  \\\n",
       "1071  let our journalists help you make sense of the...                   -1   \n",
       "1099  let our journalists help you make sense of the...                   -2   \n",
       "1413  on march   a white gunman killed eight people ...                    2   \n",
       "410   the populist wave in politics on both sides of...                    0   \n",
       "1061  let our journalists help you make sense of the...                    2   \n",
       "\n",
       "      5_step_classifier  \n",
       "1071                 -1  \n",
       "1099                 -2  \n",
       "1413                  2  \n",
       "410                   0  \n",
       "1061                  2  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ea29328-35c4-4bc3-81cf-ab77a9c89765",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.drop(columns = \"discrete_bias_score\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da3c30ae-dd2b-4e9e-88d3-98ab2fc8db42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdate</th>\n",
       "      <th>urls</th>\n",
       "      <th>pre_process_text</th>\n",
       "      <th>5_step_classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>2021-03-15</td>\n",
       "      <td>www.newyorker.com</td>\n",
       "      <td>let our journalists help you make sense of the...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>www.motherjones.com</td>\n",
       "      <td>let our journalists help you make sense of the...</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1413</th>\n",
       "      <td>2021-03-22</td>\n",
       "      <td>www.huffpost.com</td>\n",
       "      <td>on march   a white gunman killed eight people ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>www.cnn.com</td>\n",
       "      <td>the populist wave in politics on both sides of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>2021-01-21</td>\n",
       "      <td>www.newyorker.com</td>\n",
       "      <td>let our journalists help you make sense of the...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pdate                 urls  \\\n",
       "1071  2021-03-15    www.newyorker.com   \n",
       "1099  2021-03-02  www.motherjones.com   \n",
       "1413  2021-03-22     www.huffpost.com   \n",
       "410   2020-01-26          www.cnn.com   \n",
       "1061  2021-01-21    www.newyorker.com   \n",
       "\n",
       "                                       pre_process_text  5_step_classifier  \n",
       "1071  let our journalists help you make sense of the...                 -1  \n",
       "1099  let our journalists help you make sense of the...                 -2  \n",
       "1413  on march   a white gunman killed eight people ...                  2  \n",
       "410   the populist wave in politics on both sides of...                  0  \n",
       "1061  let our journalists help you make sense of the...                  2  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f696c5ef-df15-41b6-9059-fea97fb147c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0c71d26-9bda-49f3-b905-a0360645095b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee63cd1e-95c6-40b2-b076-5719a99e05d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pdate</th>\n",
       "      <th>urls</th>\n",
       "      <th>pre_process_text</th>\n",
       "      <th>5_step_classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1071</td>\n",
       "      <td>2021-03-15</td>\n",
       "      <td>www.newyorker.com</td>\n",
       "      <td>let our journalists help you make sense of the...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1099</td>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>www.motherjones.com</td>\n",
       "      <td>let our journalists help you make sense of the...</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1413</td>\n",
       "      <td>2021-03-22</td>\n",
       "      <td>www.huffpost.com</td>\n",
       "      <td>on march   a white gunman killed eight people ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>410</td>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>www.cnn.com</td>\n",
       "      <td>the populist wave in politics on both sides of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1061</td>\n",
       "      <td>2021-01-21</td>\n",
       "      <td>www.newyorker.com</td>\n",
       "      <td>let our journalists help you make sense of the...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index       pdate                 urls  \\\n",
       "0   1071  2021-03-15    www.newyorker.com   \n",
       "1   1099  2021-03-02  www.motherjones.com   \n",
       "2   1413  2021-03-22     www.huffpost.com   \n",
       "3    410  2020-01-26          www.cnn.com   \n",
       "4   1061  2021-01-21    www.newyorker.com   \n",
       "\n",
       "                                    pre_process_text  5_step_classifier  \n",
       "0  let our journalists help you make sense of the...                 -1  \n",
       "1  let our journalists help you make sense of the...                 -2  \n",
       "2  on march   a white gunman killed eight people ...                  2  \n",
       "3  the populist wave in politics on both sides of...                  0  \n",
       "4  let our journalists help you make sense of the...                  2  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25389a2c-4601-45ef-94d8-898ebfc5ac10",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "\n",
    "three_hot_dict = {-1 : [1,0,0],\n",
    "                  0 : [0,1,0],\n",
    "                  1 : [0,0,1]}\n",
    "\n",
    "five_hot_dict = {-2 : [1,0,0,0,0],\n",
    "                 -1 : [0,1,0,0,0],\n",
    "                 0 : [0,0,1,0,0],\n",
    "                 1 : [0,0,0,1,0],\n",
    "                 2 : [0,0,0,0,1]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "893fb588-d188-4c4d-afac-4dd7336361bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_score_encoding(df, n):\n",
    "\n",
    "    if n == 5:\n",
    "        df[\"one_hot_discrete\"] = df[\"5_step_classifier\"].map(five_hot_dict)\n",
    "\n",
    "    if n == 3:\n",
    "        df[\"one_hot_discrete\"] = df[\"3_step_classifier\"].map(three_hot_dict)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb313dd-5de3-4a7a-aaf3-f67ef98f7d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = bias_score_encoding(df,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ae56002-244c-404b-8bf5-373b2ad25a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_class_get_X_and_y(df):\n",
    "    \"\"\"\n",
    "    xxxxxxxxxx\n",
    "    \"\"\"\n",
    "\n",
    "    X = df[\"pre_process_text\"].tolist()\n",
    "    y = df[\"one_hot_discrete\"].tolist()\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1a8372-1ba4-4111-a92c-d933376c400f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = n_class_get_X_and_y(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8874099e-358c-4948-b928-b6e24c138ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantiate_tokenizer(model_name = IM_MODEL_NAME):\n",
    "    \"\"\"\n",
    "    Define the tokenizer we want to use in our modelling.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    return tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2377ba99-d1a4-4d6f-b690-4bf1c99c5708",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = instantiate_tokenizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efe93599-af4c-46b6-b396-9b5579482fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_tokenizer(X,\n",
    "                   tokenizer,\n",
    "                   max_len = IM_TOKEN_MAX_LEN,\n",
    "                   truncation = True,\n",
    "                   padding = \"max_length\"):\n",
    "    \"\"\"\n",
    "    Returns a dictionary of tokenized text with 2 keys: \"input_ids\" and \"attention_mask\".\n",
    "    These 2 keys are required for the input into the DistilBert model.\n",
    "    \"\"\"\n",
    "\n",
    "    tokens = tokenizer(X, max_length = max_len, truncation = truncation, padding = padding)\n",
    "\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2437ed8d-6b9b-4265-bf51-010e7f6ef49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = text_tokenizer(X, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94ef9df3-e7a0-4f7f-bcbc-feff08fa914c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_dataset_constructor(tokens,\n",
    "                           y):\n",
    "    \"\"\"\n",
    "    Using the tokenized input from the text_tokenizer function,\n",
    "    returns TensorFlow objects for use in the DistilBert model.\n",
    "    \"\"\"\n",
    "\n",
    "    tfdataset = tf.data.Dataset.from_tensor_slices((dict(tokens),y))\n",
    "\n",
    "    return tfdataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e865a331-9f91-41f9-97cf-8b59c123b5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfdataset = tf_dataset_constructor(tokens, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ff4c129-f44e-49d5-8229-4237ab37867e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X,\n",
    "                     tfdataset,\n",
    "                     test_split = IM_TEST_SPLIT,\n",
    "                     val_split = IM_VALIDATION_SPLIT,\n",
    "                     batch_size = IM_BATCH_SIZE):\n",
    "    \"\"\"\n",
    "    This function splits the TensorFlow object created in the tf_dataset_constructor function\n",
    "    into train, valdiation and test sets.\n",
    "    \"\"\"\n",
    "\n",
    "    # get the sizes of the train and validation sets\n",
    "    train_size = int(len(X) * (1-test_split))\n",
    "    val_size = int(train_size * val_split)\n",
    "\n",
    "    # shuffle the full dataset\n",
    "    tfdataset = tfdataset.shuffle(len(X))\n",
    "\n",
    "    # from the full datset, get out the train, validation and test sets\n",
    "    tfdataset_train = tfdataset.take(train_size)\n",
    "    tfdataset_val = tfdataset.skip(train_size - val_size).take(val_size)\n",
    "    tfdataset_test = tfdataset.skip(train_size)\n",
    "\n",
    "    # batch the train, validation and test sets\n",
    "    tfdataset_train = tfdataset_train.batch(batch_size)\n",
    "    tfdataset_val = tfdataset_val.batch(batch_size)\n",
    "    tfdataset_test = tfdataset_test.batch(batch_size)\n",
    "\n",
    "    return tfdataset_train, tfdataset_val, tfdataset_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c033aeb5-270b-4e65-af2c-bbdc88882919",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfdataset_train, tfdataset_val, tfdataset_test = train_test_split(X, tfdataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0a1a71e-088f-48c6-ae65-039a3b49e076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_class_ideology_model(tfdataset_train,\n",
    "                           tfdataset_val,\n",
    "                           n,\n",
    "                           model_name = IM_MODEL_NAME,\n",
    "                           learning_rate = IM_LEARNING_RATE,\n",
    "                           batch_size = IM_BATCH_SIZE,\n",
    "                           epochs = IM_EPOCHS,\n",
    "                           patience = IM_PATIENCE):\n",
    "\n",
    "    \"\"\"\n",
    "    Set up an run a DistilBert model on our TensorFlow training dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    # set up model\n",
    "    model = TFDistilBertForSequenceClassification.from_pretrained(model_name, num_labels = n)\n",
    "\n",
    "    # define loss function\n",
    "    loss = losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "    # define optimizer to be used to minimise loss\n",
    "    optimizer = optimizers.Adam(learning_rate)\n",
    "\n",
    "    # compile model\n",
    "    model.compile(optimizer = optimizer,\n",
    "                  loss = loss,\n",
    "                  metrics = \"accuracy\")\n",
    "\n",
    "    # fit model\n",
    "    model.fit(tfdataset_train,\n",
    "              batch_size = batch_size,\n",
    "              epochs = epochs,\n",
    "              validation_data = tfdataset_val,\n",
    "              callbacks = EarlyStopping(patience = patience, restore_best_weights = True))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d864994-ae74-4def-a4d8-bb2151545ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = n_class_ideology_model(tfdataset_train,tfdataset_val,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1bfeecd-221d-49ec-9ae5-be24749db71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ideology_model_predictor(model,\n",
    "                             tokens):\n",
    "    \"\"\"\n",
    "    This function uses the model output from the ideology_model function to output the\n",
    "    probabilities of each individual article being left or right wing (0 = left wing,\n",
    "    1 = right wing). As the model spits out log odds rather than probabilities, these\n",
    "    also need to be converted in this function into probabilities.\n",
    "    \"\"\"\n",
    "\n",
    "    # firstly create a TensorFlow version of our tokenized dataset without our y\n",
    "    tfdataset_no_y = tf.data.Dataset.from_tensor_slices(dict(tokens))\n",
    "\n",
    "    # use this to get out the logits for our model\n",
    "    pred_logits = model.predict(tfdataset_no_y)[0]\n",
    "\n",
    "    # convert these into probabilties\n",
    "    pred_probas = tf.nn.softmax(pred_logits).numpy()\n",
    "\n",
    "    return pred_probas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828168ff-f762-4b76-a451-010fea5302b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probas = ideology_model_predictor(model, tokens)\n",
    "pred_probas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "941ee4bd-5a5e-45a1-ad3e-80ccf03940d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_class(pred_probas):\n",
    "\n",
    "    top_class_list = []\n",
    "\n",
    "    for row in range(len(pred_probas)):\n",
    "\n",
    "        conversion_dict = {0 : \"left\",\n",
    "                       1 : \"leans left\",\n",
    "                       2 : \"centre\",\n",
    "                       3 : \"leans right\",\n",
    "                       4 : \"right\"}\n",
    "\n",
    "        top_class_list.append(conversion_dict[np.argmax(pred_probas[row])])\n",
    "\n",
    "    return top_class_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6fe9a2-3a43-43e7-8077-be65d75e8822",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_class_list = top_class(pred_probas)\n",
    "top_class_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b1c09fd-0fdd-47ec-8f2c-f1b2f1106f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_class_probas(pred_probas):\n",
    "\n",
    "    top_class_probas_list = []\n",
    "\n",
    "    for row in range(len(pred_probas)):\n",
    "        top_class_probas_list.append(max(pred_probas[row]))\n",
    "\n",
    "    return top_class_probas_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f8c9f0-617d-489f-be2b-437b1deea506",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_class_probas_list = top_class_probas(pred_probas)\n",
    "top_class_probas_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9da4f25b-9701-44df-960a-d24dc7dce6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_class_certainty(top_class_probas_list):\n",
    "\n",
    "    top_class_certainty_list = []\n",
    "\n",
    "    for prob in top_class_probas_list:\n",
    "\n",
    "        if prob > 0.8:\n",
    "            top_class_certainty_list.append(\"highly certain\")\n",
    "\n",
    "        elif prob > 0.6:\n",
    "            top_class_certainty_list.append(\"certain\")\n",
    "\n",
    "        elif prob > 0.4:\n",
    "            top_class_certainty_list.append(\"fairly certain\")\n",
    "\n",
    "        else:\n",
    "            top_class_certainty_list.append(\"low certainty\")\n",
    "\n",
    "\n",
    "    return top_class_certainty_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c62971-8207-4c7b-bf2d-a61f11baf565",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_class_certainty_list = top_class_certainty(top_class_probas_list)\n",
    "top_class_certainty_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d98c11f-14dd-4302-98ff-3600fd45311e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_n_class_ideology_model(df, n):\n",
    "\n",
    "    df = bias_score_encoding(df, n)\n",
    "\n",
    "    X, y = n_class_get_X_and_y(df)\n",
    "\n",
    "    tokenizer = instantiate_tokenizer(model_name = IM_MODEL_NAME)\n",
    "\n",
    "    tokens = text_tokenizer(X,\n",
    "                            tokenizer,\n",
    "                            max_len = IM_TOKEN_MAX_LEN,\n",
    "                            truncation = True,\n",
    "                            padding = \"max_length\")\n",
    "\n",
    "    tfdataset = tf_dataset_constructor(tokens, y)\n",
    "\n",
    "    # the following function automatically returns the test dataset, even though this is\n",
    "    # not used further, as we do not evaluate the model accuracy within this function.\n",
    "\n",
    "    tfdataset_train, tfdataset_val, tfdataset_test =\\\n",
    "    train_test_split(X,\n",
    "                    tfdataset,\n",
    "                    test_split = IM_TEST_SPLIT,\n",
    "                    val_split = IM_VALIDATION_SPLIT,\n",
    "                    batch_size = IM_BATCH_SIZE)\n",
    "\n",
    "    model = n_class_ideology_model(tfdataset_train,\n",
    "                           tfdataset_val,\n",
    "                           n,\n",
    "                           model_name = IM_MODEL_NAME,\n",
    "                           learning_rate = IM_LEARNING_RATE,\n",
    "                           batch_size = IM_BATCH_SIZE,\n",
    "                           epochs = IM_EPOCHS,\n",
    "                           patience = IM_PATIENCE)\n",
    "\n",
    "    pred_probas = ideology_model_predictor(model, tokens)\n",
    "\n",
    "    top_class_list = top_class(pred_probas)\n",
    "    top_class_probas_list = top_class_probas(pred_probas)\n",
    "    top_class_certainty_list = top_class_certainty(top_class_probas_list)\n",
    "\n",
    "    df[\"pred_class\"] = top_class_list\n",
    "    df[\"pred_class_proba\"] = top_class_probas_list\n",
    "    df[\"pred_class_certainty\"] = top_class_certainty_list\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaf695b-7f0c-470e-b76f-54c73fc60916",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 1/20 [>.............................] - ETA: 4:21 - loss: 0.6801 - accuracy: 0.5000"
     ]
    }
   ],
   "source": [
    "output_df = full_n_class_ideology_model(df,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25ef82a-f20b-4fe1-8124-1e787193b760",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2acff2b9-97ed-497d-a513-c5a3fd98b296",
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_us_dict = {\"msnbc.com\" : \"US\",\n",
    "\"theatlantic.com\" : \"US\",\n",
    "\"alternet.org\" : \"US\",\n",
    "\"thedailybeast.com\" : \"US\",\n",
    "\"huffpost.com\" : \"US\",\n",
    "\"theintercept.com\" : \"US\",\n",
    "\"jacobinmag.com\" : \"US\",\n",
    "\"democracynow.org\" : \"US\",\n",
    "\"motherjones.com\" : \"US\",\n",
    "\"newyorker.com\" : \"US\",\n",
    "\"thenation.com\" : \"US\",\n",
    "\"slate.com\" : \"US\",\n",
    "\"vox.com\" : \"US\",\n",
    "\"yahoo.com\" : \"US\",\n",
    "\"abcnews.go.com\" : \"US\",\n",
    "\"theguardian.com\" : \"UK\",\n",
    "\"bloomberg.com\" : \"US\",\n",
    "\"time.com\" : \"US\",\n",
    "\"npr.org\" : \"US\",\n",
    "\"propublica.org\" : \"US\",\n",
    "\"insider.com\" : \"US\",\n",
    "\"nbcnews.com\" : \"US\",\n",
    "\"nytimes.com\" : \"US\",\n",
    "\"axios.com\" : \"US\",\n",
    "\"cbsnews.com\" : \"US\",\n",
    "\"apnews.com\" : \"US\",\n",
    "\"cnn.com\" : \"US\",\n",
    "\"washingtonpost.com\" : \"US\",\n",
    "\"usatoday.com\" : \"US\",\n",
    "\"politico.com\" : \"US\",\n",
    "\"bbc.com\" : \"UK\",\n",
    "\"csmonitor.com\" : \"US\",\n",
    "\"forbes.com\" : \"US\",\n",
    "\"thehill.com\" : \"US\",\n",
    "\"reuters.com\" : \"UK\",\n",
    "\"newsweek.com\" : \"US\",\n",
    "\"marketwatch.com\" : \"US\",\n",
    "\"newsnationnow.com\" : \"US\",\n",
    "\"realclearpolitics.com\" : \"US\",\n",
    "\"wsj.com\" : \"US\",\n",
    "\"thedispatch.com\" : \"US\",\n",
    "\"theepochtimes.com\" : \"US\",\n",
    "\"nypost.com\" : \"US\",\n",
    "\"nationalreview.com\" : \"US\",\n",
    "\"foxbusiness.com\" : \"US\",\n",
    "\"reason.com\" : \"US\",\n",
    "\"washingtonexaminer.com\" : \"US\",\n",
    "\"washingtontimes.com\" : \"US\",\n",
    "\"foxnews.com\" : \"US\",\n",
    "\"spectator.org\" : \"US\",\n",
    "\"breitbart.com\" : \"US\",\n",
    "\"theamericanconservative.com\" : \"US\",\n",
    "\"theblaze.com\" : \"US\",\n",
    "\"dailycaller.com\" : \"US\",\n",
    "\"cbn.com\" : \"US\",\n",
    "\"dailywire.com\" : \"US\",\n",
    "\"thepostmillennial.com\" : \"Canada\",\n",
    "\"dailymail.co.uk\" : \"UK\",\n",
    "\"thefederalist.com\" : \"US\",\n",
    "\"ijr.com\" : \"US\",\n",
    "\"newsmax.com\" : \"US\",\n",
    "\"freebeacon.com\" : \"US\",\n",
    "\"oann.com\" : \"US\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06172cd2-256e-46ee-9e4d-3d0e9c1681de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['msnbc.com',\n",
       " 'theatlantic.com',\n",
       " 'alternet.org',\n",
       " 'thedailybeast.com',\n",
       " 'huffpost.com',\n",
       " 'theintercept.com',\n",
       " 'jacobinmag.com',\n",
       " 'democracynow.org',\n",
       " 'motherjones.com',\n",
       " 'newyorker.com',\n",
       " 'thenation.com',\n",
       " 'slate.com',\n",
       " 'vox.com',\n",
       " 'yahoo.com',\n",
       " 'abcnews.go.com',\n",
       " 'theguardian.com',\n",
       " 'bloomberg.com',\n",
       " 'time.com',\n",
       " 'npr.org',\n",
       " 'propublica.org',\n",
       " 'insider.com',\n",
       " 'nbcnews.com',\n",
       " 'nytimes.com',\n",
       " 'axios.com',\n",
       " 'cbsnews.com',\n",
       " 'apnews.com',\n",
       " 'cnn.com',\n",
       " 'washingtonpost.com',\n",
       " 'usatoday.com',\n",
       " 'politico.com',\n",
       " 'bbc.com',\n",
       " 'csmonitor.com',\n",
       " 'forbes.com',\n",
       " 'thehill.com',\n",
       " 'reuters.com',\n",
       " 'newsweek.com',\n",
       " 'marketwatch.com',\n",
       " 'newsnationnow.com',\n",
       " 'realclearpolitics.com',\n",
       " 'wsj.com',\n",
       " 'thedispatch.com',\n",
       " 'theepochtimes.com',\n",
       " 'nypost.com',\n",
       " 'nationalreview.com',\n",
       " 'foxbusiness.com',\n",
       " 'reason.com',\n",
       " 'washingtonexaminer.com',\n",
       " 'washingtontimes.com',\n",
       " 'foxnews.com',\n",
       " 'spectator.org',\n",
       " 'breitbart.com',\n",
       " 'theamericanconservative.com',\n",
       " 'theblaze.com',\n",
       " 'dailycaller.com',\n",
       " 'cbn.com',\n",
       " 'dailywire.com',\n",
       " 'thepostmillennial.com',\n",
       " 'dailymail.co.uk',\n",
       " 'thefederalist.com',\n",
       " 'ijr.com',\n",
       " 'newsmax.com',\n",
       " 'freebeacon.com',\n",
       " 'oann.com']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(uk_us_dict.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8a9cb3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlist\u001b[39m(\u001b[43mdf\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murls\u001b[39m\u001b[38;5;124m\"\u001b[39m])[\u001b[38;5;241m17\u001b[39m][\u001b[38;5;241m4\u001b[39m:]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "list(df[\"urls\"])[17][4:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca12eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_us_dict[list(df[\"urls\"])[0][4:]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45392cb-d8fe-4643-9abd-4732dd6db142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_country_source(df):\n",
    "\n",
    "    country_list = []\n",
    "\n",
    "    for i in range(len(df[\"urls\"])):\n",
    "\n",
    "        if list(df[\"urls\"])[i] in list(uk_us_dict.keys()):\n",
    "            country_list.append(uk_us_dict[list(df[\"urls\"])[i]])\n",
    "\n",
    "        # removing \"www.\" from the beginnging of URLs if present\n",
    "        elif list(df[\"urls\"])[i][4:] in list(uk_us_dict.keys()):\n",
    "            country_list.append(uk_us_dict[list(df[\"urls\"])[i][4:]])\n",
    "\n",
    "        # removing \"www1.\" or \"www2.\" from the beginnging of URLs if present\n",
    "        elif list(df[\"urls\"])[i][5:] in list(uk_us_dict.keys()):\n",
    "            country_list.append(uk_us_dict[list(df[\"urls\"])[i][5:]])\n",
    "\n",
    "        else:\n",
    "            country_list.append(\"country unknown\")\n",
    "\n",
    "    df[\"country\"] = country_list\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236416c1-2b86-4b8a-a1bd-ee55b5fa7115",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = add_country_source(df)\n",
    "\n",
    "new_df.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbff7c9c-09f3-481e-b7ac-f26a03b81b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edb2ba8-0f80-4b87-812c-240d1fecec2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df.drop_duplicates(subset = [\"urls\"], keep='first', ignore_index=True)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc39b6d6-33c3-4648-a7a4-abc08a3bc572",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb2f0d5-93fc-4d35-898a-e80d8bd87f10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238e8e9c-37ee-4203-b2f3-d47c9c472647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5429d6-48af-4c45-a76b-746daa59765a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "207cae1a-8dc6-40dd-a739-f5c848953043",
   "metadata": {},
   "source": [
    "## The below is a working model based on binary classification only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fc7a9e-4b1c-454a-bef4-5f39d800cc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "IM_MODEL_NAME = \"distilbert-base-uncased\"\n",
    "IM_BATCH_SIZE = 2\n",
    "IM_LEARNING_RATE = 3e-5\n",
    "IM_TOKEN_MAX_LEN = 50   ### currently set at 50 to speed up basic model training\n",
    "IM_TEST_SPLIT = 0.2\n",
    "IM_VALIDATION_SPLIT = 0.3   ### refers to split withing training data (not whole dataset)\n",
    "IM_EPOCHS = 5   ### currently set to 5 to speed up basic model training\n",
    "IM_PATIENCE = 2   ### currently set to 2 due to the low number of epochs (5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1719ab50-f56d-4f99-82f1-06b15d43dd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_and_y(df):\n",
    "    \"\"\"\n",
    "    Gets from our dataset: (i) the feature (i.e. X - the pre-processed text);\n",
    "    and (ii) the target (i.e. y - the ideology: left wing = 0 / right wing = 1).\n",
    "    These need to be converted into lists for use in our model.\n",
    "    \"\"\"\n",
    "\n",
    "    X = df[\"pre_process_text\"].tolist()\n",
    "    y = df[\"classifier\"].tolist()\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb293e6-ebdc-4a50-b2ad-7ff6cc55c436",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantiate_tokenizer(model_name = IM_MODEL_NAME):\n",
    "    \"\"\"\n",
    "    Define the tokenizer we want to use in our modelling.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    return tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77ea881-76ec-4910-b7d6-2141bdde68af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_tokenizer(X,\n",
    "                   tokenizer,\n",
    "                   max_len = IM_TOKEN_MAX_LEN,\n",
    "                   truncation = True,\n",
    "                   padding = \"max_length\"):\n",
    "    \"\"\"\n",
    "    Returns a dictionary of tokenized text with 2 keys: \"input_ids\" and \"attention_mask\".\n",
    "    These 2 keys are required for the input into the DistilBert model.\n",
    "    \"\"\"\n",
    "\n",
    "    tokens = tokenizer(X, max_length = max_len, truncation = truncation, padding = padding)\n",
    "\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17789585-6507-4452-a251-69c4c0bfd4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_dataset_constructor(tokens,\n",
    "                           y):\n",
    "    \"\"\"\n",
    "    Using the tokenized input from the text_tokenizer function,\n",
    "    returns TensorFlow objects for use in the DistilBert model.\n",
    "    \"\"\"\n",
    "\n",
    "    tfdataset = tf.data.Dataset.from_tensor_slices((dict(tokens),y))\n",
    "\n",
    "    return tfdataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d165d5f-d65f-47c7-b763-cc24f5ceb853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X,\n",
    "                     tfdataset,\n",
    "                     test_split = IM_TEST_SPLIT,\n",
    "                     val_split = IM_VALIDATION_SPLIT,\n",
    "                     batch_size = IM_BATCH_SIZE):\n",
    "    \"\"\"\n",
    "    This function splits the TensorFlow object created in the tf_dataset_constructor function\n",
    "    into train, valdiation and test sets.\n",
    "    \"\"\"\n",
    "\n",
    "    # get the sizes of the train and validation sets\n",
    "    train_size = int(len(X) * (1-test_split))\n",
    "    val_size = int(train_size * val_split)\n",
    "\n",
    "    # shuffle the full dataset\n",
    "    tfdataset = tfdataset.shuffle(len(X))\n",
    "\n",
    "    # from the full datset, get out the train, validation and test sets\n",
    "    tfdataset_train = tfdataset.take(train_size)\n",
    "    tfdataset_val = tfdataset.skip(train_size - val_size).take(val_size)\n",
    "    tfdataset_test = tfdataset.skip(train_size)\n",
    "\n",
    "    # batch the train, validation and test sets\n",
    "    tfdataset_train = tfdataset_train.batch(batch_size)\n",
    "    tfdataset_val = tfdataset_val.batch(batch_size)\n",
    "    tfdataset_test = tfdataset_test.batch(batch_size)\n",
    "\n",
    "    return tfdataset_train, tfdataset_val, tfdataset_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a621268-ded6-40bf-a2f2-5c0c5a6a9a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ideology_model(tfdataset_train,\n",
    "                   tfdataset_val,\n",
    "                   model_name = IM_MODEL_NAME,\n",
    "                   learning_rate = IM_LEARNING_RATE,\n",
    "                   batch_size = IM_BATCH_SIZE,\n",
    "                   epochs = IM_EPOCHS,\n",
    "                   patience = IM_PATIENCE):\n",
    "\n",
    "    \"\"\"\n",
    "    Set up an run a DistilBert model on our TensorFlow training dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    # set up model\n",
    "    model = TFDistilBertForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "    # define loss function\n",
    "    loss = losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    # define optimizer to be used to minimise loss\n",
    "    optimizer = optimizers.Adam(learning_rate)\n",
    "\n",
    "    # compile model\n",
    "    model.compile(optimizer = optimizer,\n",
    "                  loss = loss,\n",
    "                  metrics = \"accuracy\")\n",
    "\n",
    "    # fit model\n",
    "    model.fit(tfdataset_train,\n",
    "              batch_size = batch_size,\n",
    "              epochs = epochs,\n",
    "              validation_data = tfdataset_val,\n",
    "              callbacks = EarlyStopping(patience = patience, restore_best_weights = True))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a35442-194d-4128-b27b-153bc7651617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ideology_model_evaluator(model,\n",
    "                             tfdataset_test,\n",
    "                             batch_size = IM_BATCH_SIZE):\n",
    "    \"\"\"\n",
    "    Evaluate our model on the TensorFlow test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    benchmarks = model.evaluate(tfdataset_test, batch_size = batch_size, return_dict = True)\n",
    "    accuracy = benchmarks[\"accuracy\"]\n",
    "\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8eec605-65bf-41b0-869a-edd2ca01ad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ideology_model_predictor(model,\n",
    "                             tokens):\n",
    "    \"\"\"\n",
    "    This function uses the model output from the ideology_model function to output the\n",
    "    probabilities of each individual article being left or right wing (0 = left wing,\n",
    "    1 = right wing). As the model spits out log odds rather than probabilities, these\n",
    "    also need to be converted in this function into probabilities.\n",
    "    \"\"\"\n",
    "\n",
    "    # firstly create a TensorFlow version of our tokenized dataset without our y\n",
    "    tfdataset_no_y = tf.data.Dataset.from_tensor_slices(dict(tokens))\n",
    "\n",
    "    # use this to get out the logits for our model\n",
    "    pred_logits = model.predict(tfdataset_no_y)[0]\n",
    "\n",
    "    # convert these into probabilties\n",
    "    pred_probas = tf.nn.softmax(pred_logits).numpy()\n",
    "\n",
    "    return pred_probas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbbf2c9-32fb-4de5-a158-13a35e8163e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_ideology_model(df):\n",
    "    \"\"\"\n",
    "    Combine all above functions into one master function, except for the\n",
    "    ideology_model_evaluator function, as we do not need the accuracy output here.\n",
    "    \"\"\"\n",
    "\n",
    "    X, y = get_X_and_y(df)\n",
    "\n",
    "    tokenizer = instantiate_tokenizer(model_name = IM_MODEL_NAME)\n",
    "\n",
    "    tokens = text_tokenizer(X,\n",
    "                            tokenizer,\n",
    "                            max_len = IM_TOKEN_MAX_LEN,\n",
    "                            truncation = True,\n",
    "                            padding = \"max_length\")\n",
    "\n",
    "    tfdataset = tf_dataset_constructor(tokens, y)\n",
    "\n",
    "    # the following function automatically returns the test dataset, even though this is\n",
    "    # not used further, as we do not evaluate the model accuracy within this function.\n",
    "\n",
    "    tfdataset_train, tfdataset_val, tfdataset_test =\\\n",
    "    train_test_split(X,\n",
    "                    tfdataset,\n",
    "                    test_split = IM_TEST_SPLIT,\n",
    "                    val_split = IM_VALIDATION_SPLIT,\n",
    "                    batch_size = IM_BATCH_SIZE)\n",
    "\n",
    "    model = ideology_model(tfdataset_train,\n",
    "                           tfdataset_val,\n",
    "                           model_name = IM_MODEL_NAME,\n",
    "                           learning_rate = IM_LEARNING_RATE,\n",
    "                           batch_size = IM_BATCH_SIZE,\n",
    "                           epochs = IM_EPOCHS,\n",
    "                           patience = IM_PATIENCE)\n",
    "\n",
    "\n",
    "    pred_probas = ideology_model_predictor(model, tokens)\n",
    "\n",
    "    # from the predicted probabilities, we want the second column, which shows the probability\n",
    "    # of the article being right-wing - a score near to 1 is very right wing; a score near to 0\n",
    "    # is very left wing. We then add this column onto our df and return the full df.\n",
    "\n",
    "    df['pred_probas'] = pred_probas[:,1]\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fe6856-22a6-44bf-a92a-36c83670c2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = full_ideology_model(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13c2803-dfdc-4c7e-a658-dfa60ae4e8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cf6326-c597-4d4a-87f2-1b6969baf22c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
