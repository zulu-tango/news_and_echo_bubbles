{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc26e6f6-51c0-41e0-b1d6-fd78cf9a17b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 17:16:59.822641: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-01 17:16:59.871051: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-01 17:17:00.137906: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-01 17:17:00.137951: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-01 17:17:00.185205: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-01 17:17:00.274508: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-01 17:17:00.275876: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-01 17:17:01.342078: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers, losses\n",
    "from transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d4ce87be-03e3-4e8d-ad6d-422704f4144b",
   "metadata": {},
   "outputs": [],
   "source": [
    "IM_MODEL_NAME = \"distilbert-base-uncased\"\n",
    "IM_BATCH_SIZE = 2\n",
    "IM_LEARNING_RATE = 3e-5\n",
    "IM_TOKEN_MAX_LEN = 50   ### currently set at 50 to speed up basic model training\n",
    "IM_TEST_SPLIT = 0.2\n",
    "IM_VALIDATION_SPLIT = 0.3   ### refers to split withing training data (not whole dataset)\n",
    "IM_EPOCHS = 5   ### currently set to 5 to speed up basic model training\n",
    "IM_PATIENCE = 2   ### currently set to 2 due to the low number of epochs (5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02dd374c-5a1b-4007-aa9e-439aea47bfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "344bd4f5-a4d4-4a60-981b-eaedd20d59f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/connor/code/zulu-tango/news_and_echo_bubbles/raw_data/cleaned.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72aa192c-4318-433b-9fcb-272932b3edc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop irrelevant columns and take a sample of 50 to test\n",
    "df = df.drop(columns = [\"link\", \"pdate\", \"title\", \"author\", \"text\", \"keywords\", \"tags\", \"compound\",\\\n",
    "                            \"neg\", \"neu\", \"pos\", \"polarity\", \"subjectivity\", \"time\", \"urls\"]).sample(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7584eec2-cb12-4bb2-9c92-f69df51ca1b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>pre_process_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>0</td>\n",
       "      <td>a trump statue has caught on with china’s onli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219</th>\n",
       "      <td>1</td>\n",
       "      <td>sen  ben sasse on capitol hill in washington  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2347</th>\n",
       "      <td>1</td>\n",
       "      <td>rising domestic supply and great efficiency ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2117</th>\n",
       "      <td>1</td>\n",
       "      <td>republican south dakota gov  kristi noem on sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2418</th>\n",
       "      <td>1</td>\n",
       "      <td>president biden’s  build back better  campaign...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      classifier                                   pre_process_text\n",
       "245            0  a trump statue has caught on with china’s onli...\n",
       "2219           1  sen  ben sasse on capitol hill in washington  ...\n",
       "2347           1  rising domestic supply and great efficiency ga...\n",
       "2117           1  republican south dakota gov  kristi noem on sa...\n",
       "2418           1  president biden’s  build back better  campaign..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4ee0345-36cd-41d4-b7b5-906787a9b2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_list = [-1.89, -1.02, 1.6, 3.65, 2.8, -2.47, 1.39, 2.78, -3.65, -3.4, -3.48, 2.44, -4.07, -4.28, 4.71, 3.03, -0.68, 3.05, 0.06,\\\n",
    "                   4.86, 0.31, 2.18, -0.31, -3.47, -1.99, 1.81, -0.91, -1.17, 3.34, 1.41, -2.23, -3.17, 2.58, -3.13, -1.23, 0.56, 4.48, 3.48,\\\n",
    "                   -2.48, 3.37, -4.81, -1.84, -0.42, 4.94, 4.14, -1.59, 0.16, -4.29, -4.24, -4.23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0dcb7129-0899-4690-b88c-07c18bccc0c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(continuous_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48909374-e468-4b0c-b771-d2ff6756327e",
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_list = [-1, -2, 2, 0, 2, 0, 1, 0, 0, 2, 2, 1, 2, 0, -1, 2, -2, -2, -1, -2, 2, 1, 2, 1, 1, -1, -2, 2, 1, -2, -2, 2, -1, 0, 0,\\\n",
    "                 -1, -1, -2, 0, 1, -1, 1, 2, -1, 0, 1, 2, 2, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9dd3749-d1aa-4fd6-835f-ba0927f75f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(discrete_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6da7767-d1c2-4097-bee9-eb59e98f32d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>pre_process_text</th>\n",
       "      <th>continuous_bias_score</th>\n",
       "      <th>discrete_bias_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>0</td>\n",
       "      <td>a trump statue has caught on with china’s onli...</td>\n",
       "      <td>-1.89</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219</th>\n",
       "      <td>1</td>\n",
       "      <td>sen  ben sasse on capitol hill in washington  ...</td>\n",
       "      <td>-1.02</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2347</th>\n",
       "      <td>1</td>\n",
       "      <td>rising domestic supply and great efficiency ga...</td>\n",
       "      <td>1.60</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2117</th>\n",
       "      <td>1</td>\n",
       "      <td>republican south dakota gov  kristi noem on sa...</td>\n",
       "      <td>3.65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2418</th>\n",
       "      <td>1</td>\n",
       "      <td>president biden’s  build back better  campaign...</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      classifier                                   pre_process_text  \\\n",
       "245            0  a trump statue has caught on with china’s onli...   \n",
       "2219           1  sen  ben sasse on capitol hill in washington  ...   \n",
       "2347           1  rising domestic supply and great efficiency ga...   \n",
       "2117           1  republican south dakota gov  kristi noem on sa...   \n",
       "2418           1  president biden’s  build back better  campaign...   \n",
       "\n",
       "      continuous_bias_score  discrete_bias_score  \n",
       "245                   -1.89                   -1  \n",
       "2219                  -1.02                   -2  \n",
       "2347                   1.60                    2  \n",
       "2117                   3.65                    0  \n",
       "2418                   2.80                    2  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"continuous_bias_score\"] = continuous_list\n",
    "df[\"discrete_bias_score\"] = discrete_list\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9a5544c-c678-45bf-b525-9d77ad64cf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO DO: MAKE THE MODEL WORK USING THE \"CONTINUOUS_BIAS_SCORE\" AND \"DISCRETE_BIAS_SCORE\" COLUMNS\n",
    "### THE OUTPUT SHOULD STILL BE A PROBABILITY FROM 0 TO 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43e32b0f-2a46-4c23-a47a-4fa720aad24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6642e7f-e950-4add-bc63-aad57d3ed957",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "812aae04-48a7-4e91-8df4-83710012b8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_dict = {-2:[1,0,0,0,0],\n",
    "                -1:[0,1,0,0,0],\n",
    "                0:[0,0,1,0,0],\n",
    "                1:[0,0,0,1,0],\n",
    "                2:[0,0,0,0,1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b09a0b6a-f480-4218-8bd1-921058b1a415",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"one_hot_discrete\"] = df[\"discrete_bias_score\"].map(one_hot_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6792bca9-2928-482b-b663-29d08e67ed23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>pre_process_text</th>\n",
       "      <th>continuous_bias_score</th>\n",
       "      <th>discrete_bias_score</th>\n",
       "      <th>one_hot_discrete</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>0</td>\n",
       "      <td>a trump statue has caught on with china’s onli...</td>\n",
       "      <td>-1.89</td>\n",
       "      <td>-1</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219</th>\n",
       "      <td>1</td>\n",
       "      <td>sen  ben sasse on capitol hill in washington  ...</td>\n",
       "      <td>-1.02</td>\n",
       "      <td>-2</td>\n",
       "      <td>[1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2347</th>\n",
       "      <td>1</td>\n",
       "      <td>rising domestic supply and great efficiency ga...</td>\n",
       "      <td>1.60</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2117</th>\n",
       "      <td>1</td>\n",
       "      <td>republican south dakota gov  kristi noem on sa...</td>\n",
       "      <td>3.65</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2418</th>\n",
       "      <td>1</td>\n",
       "      <td>president biden’s  build back better  campaign...</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      classifier                                   pre_process_text  \\\n",
       "245            0  a trump statue has caught on with china’s onli...   \n",
       "2219           1  sen  ben sasse on capitol hill in washington  ...   \n",
       "2347           1  rising domestic supply and great efficiency ga...   \n",
       "2117           1  republican south dakota gov  kristi noem on sa...   \n",
       "2418           1  president biden’s  build back better  campaign...   \n",
       "\n",
       "      continuous_bias_score  discrete_bias_score one_hot_discrete  \n",
       "245                   -1.89                   -1  [0, 1, 0, 0, 0]  \n",
       "2219                  -1.02                   -2  [1, 0, 0, 0, 0]  \n",
       "2347                   1.60                    2  [0, 0, 0, 0, 1]  \n",
       "2117                   3.65                    0  [0, 0, 1, 0, 0]  \n",
       "2418                   2.80                    2  [0, 0, 0, 0, 1]  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5d7d02-c20f-44a0-88e8-529c1895e2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NEW_get_X_and_y(df):\n",
    "    \"\"\"\n",
    "    Gets from our dataset: (i) the feature (i.e. X - the pre-processed text);\n",
    "    and (ii) the target (i.e. y - the ideology: left wing = 0 / right wing = 1).\n",
    "    These need to be converted into lists for use in our model.\n",
    "    \"\"\"\n",
    "\n",
    "    X = df[\"pre_process_text\"].tolist()\n",
    "    y = df[\"one_hot_discrete\"].tolist()\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1828ba4-56e0-4b50-b0bf-6a8096370a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = NEW_get_X_and_y(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4da6d2-262d-424b-996b-18ba06df6d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = instantiate_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7625b5-9e80-40cc-9cdb-f138a4a998b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = text_tokenizer(X, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98978ec2-ccf4-40f9-b789-d56a34e7eb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfdataset = tf_dataset_constructor(tokens, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b218ebf4-0643-4c8e-9436-ce33a911b422",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfdataset_train, tfdataset_val, tfdataset_test = train_test_split(X, tfdataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed436443-4976-4be5-afc3-40b7a37bc9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NEW_ideology_model(tfdataset_train,\n",
    "                   tfdataset_val,\n",
    "                   model_name = IM_MODEL_NAME,\n",
    "                   learning_rate = IM_LEARNING_RATE,\n",
    "                   batch_size = IM_BATCH_SIZE,\n",
    "                   epochs = IM_EPOCHS,\n",
    "                   patience = IM_PATIENCE):\n",
    "\n",
    "    \"\"\"\n",
    "    Set up an run a DistilBert model on our TensorFlow training dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    num_labels = 5  ################\n",
    "\n",
    "    # set up model\n",
    "    model = TFDistilBertForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "\n",
    "    # define loss function\n",
    "    loss = losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "    # define optimizer to be used to minimise loss\n",
    "    optimizer = optimizers.Adam(learning_rate)\n",
    "\n",
    "    # compile model\n",
    "    model.compile(optimizer = optimizer,\n",
    "                  loss = loss,\n",
    "                  metrics = \"accuracy\")\n",
    "\n",
    "    # fit model\n",
    "    model.fit(tfdataset_train,\n",
    "              batch_size = batch_size,\n",
    "              epochs = epochs,\n",
    "              validation_data = tfdataset_val,\n",
    "              callbacks = EarlyStopping(patience = patience, restore_best_weights = True))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be63709-cc47-4b2f-aeec-6b23a5c057cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NEW_ideology_model(tfdataset_train,\n",
    "                   tfdataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261753c0-07cd-4611-a5b3-ca0e9feeb5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = ideology_model_evaluator(model, tfdataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3d1313-cb16-4c79-867c-0c754fd01259",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probas = ideology_model_predictor(model,tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d1cad6-f3d5-4b29-8195-718e4ce54434",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6283cd-c2ed-4045-84d6-bac2b77f89d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba0b12b-d8ae-479c-9c7b-fe617646656a",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_class_list = []\n",
    "\n",
    "for row in range(len(pred_probas)):\n",
    "    \n",
    "    conversion_dict = {0 : \"left\",\n",
    "                       1 : \"leans left\",\n",
    "                       2 : \"centre\",\n",
    "                       3 : \"leans right\",\n",
    "                       4 : \"right\"}\n",
    "    \n",
    "    top_class_list.append(conversion_dict[np.argmax(pred_probas[row])])\n",
    "\n",
    "print(top_class_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd1d38f-9793-4e39-9c8a-d763f2d9f954",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f769f26f-485c-48a6-8028-ab655f21f9ae",
   "metadata": {},
   "source": [
    "## TESTING IN FULL!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c3c88eb-e094-486b-a292-da105905ebc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = [\"continuous_bias_score\", \"one_hot_discrete\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48de2727-70ac-4f06-8ded-d6dbc3387ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"5_step_classifier\"] = df[\"discrete_bias_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "924c50c6-17d6-4e3e-9dc7-c082376ee706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>pre_process_text</th>\n",
       "      <th>discrete_bias_score</th>\n",
       "      <th>5_step_classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>0</td>\n",
       "      <td>a trump statue has caught on with china’s onli...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219</th>\n",
       "      <td>1</td>\n",
       "      <td>sen  ben sasse on capitol hill in washington  ...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2347</th>\n",
       "      <td>1</td>\n",
       "      <td>rising domestic supply and great efficiency ga...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2117</th>\n",
       "      <td>1</td>\n",
       "      <td>republican south dakota gov  kristi noem on sa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2418</th>\n",
       "      <td>1</td>\n",
       "      <td>president biden’s  build back better  campaign...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      classifier                                   pre_process_text  \\\n",
       "245            0  a trump statue has caught on with china’s onli...   \n",
       "2219           1  sen  ben sasse on capitol hill in washington  ...   \n",
       "2347           1  rising domestic supply and great efficiency ga...   \n",
       "2117           1  republican south dakota gov  kristi noem on sa...   \n",
       "2418           1  president biden’s  build back better  campaign...   \n",
       "\n",
       "      discrete_bias_score  5_step_classifier  \n",
       "245                    -1                 -1  \n",
       "2219                   -2                 -2  \n",
       "2347                    2                  2  \n",
       "2117                    0                  0  \n",
       "2418                    2                  2  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f696c5ef-df15-41b6-9059-fea97fb147c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "25389a2c-4601-45ef-94d8-898ebfc5ac10",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "\n",
    "three_hot_dict = {-1 : [1,0,0],\n",
    "                  0 : [0,1,0],\n",
    "                  1 : [0,0,1]}\n",
    "\n",
    "five_hot_dict = {-2 : [1,0,0,0,0],\n",
    "                 -1 : [0,1,0,0,0],\n",
    "                 0 : [0,0,1,0,0],\n",
    "                 1 : [0,0,0,1,0],\n",
    "                 2 : [0,0,0,0,1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "893fb588-d188-4c4d-afac-4dd7336361bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_score_encoding(df, n):\n",
    "\n",
    "    if n == 5:\n",
    "        df[\"one_hot_discrete\"] = df[\"5_step_classifier\"].map(five_hot_dict)\n",
    "\n",
    "    if n == 3:\n",
    "        df[\"one_hot_discrete\"] = df[\"3_step_classifier\"].map(three_hot_dict)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9ae56002-244c-404b-8bf5-373b2ad25a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_class_get_X_and_y(df):\n",
    "    \"\"\"\n",
    "    xxxxxxxxxx\n",
    "    \"\"\"\n",
    "\n",
    "    X = df[\"pre_process_text\"].tolist()\n",
    "    y = df[\"one_hot_discrete\"].tolist()\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8874099e-358c-4948-b928-b6e24c138ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantiate_tokenizer(model_name = IM_MODEL_NAME):\n",
    "    \"\"\"\n",
    "    Define the tokenizer we want to use in our modelling.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "efe93599-af4c-46b6-b396-9b5579482fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_tokenizer(X,\n",
    "                   tokenizer,\n",
    "                   max_len = IM_TOKEN_MAX_LEN,\n",
    "                   truncation = True,\n",
    "                   padding = \"max_length\"):\n",
    "    \"\"\"\n",
    "    Returns a dictionary of tokenized text with 2 keys: \"input_ids\" and \"attention_mask\".\n",
    "    These 2 keys are required for the input into the DistilBert model.\n",
    "    \"\"\"\n",
    "\n",
    "    tokens = tokenizer(X, max_length = max_len, truncation = truncation, padding = padding)\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "94ef9df3-e7a0-4f7f-bcbc-feff08fa914c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_dataset_constructor(tokens,\n",
    "                           y):\n",
    "    \"\"\"\n",
    "    Using the tokenized input from the text_tokenizer function,\n",
    "    returns TensorFlow objects for use in the DistilBert model.\n",
    "    \"\"\"\n",
    "\n",
    "    tfdataset = tf.data.Dataset.from_tensor_slices((dict(tokens),y))\n",
    "\n",
    "    return tfdataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5ff4c129-f44e-49d5-8229-4237ab37867e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X,\n",
    "                     tfdataset,\n",
    "                     test_split = IM_TEST_SPLIT,\n",
    "                     val_split = IM_VALIDATION_SPLIT,\n",
    "                     batch_size = IM_BATCH_SIZE):\n",
    "    \"\"\"\n",
    "    This function splits the TensorFlow object created in the tf_dataset_constructor function\n",
    "    into train, valdiation and test sets.\n",
    "    \"\"\"\n",
    "\n",
    "    # get the sizes of the train and validation sets\n",
    "    train_size = int(len(X) * (1-test_split))\n",
    "    val_size = int(train_size * val_split)\n",
    "\n",
    "    # shuffle the full dataset\n",
    "    tfdataset = tfdataset.shuffle(len(X))\n",
    "\n",
    "    # from the full datset, get out the train, validation and test sets\n",
    "    tfdataset_train = tfdataset.take(train_size)\n",
    "    tfdataset_val = tfdataset.skip(train_size - val_size).take(val_size)\n",
    "    tfdataset_test = tfdataset.skip(train_size)\n",
    "\n",
    "    # batch the train, validation and test sets\n",
    "    tfdataset_train = tfdataset_train.batch(batch_size)\n",
    "    tfdataset_val = tfdataset_val.batch(batch_size)\n",
    "    tfdataset_test = tfdataset_test.batch(batch_size)\n",
    "\n",
    "    return tfdataset_train, tfdataset_val, tfdataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f0a1a71e-088f-48c6-ae65-039a3b49e076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_class_ideology_model(tfdataset_train,\n",
    "                           tfdataset_val,\n",
    "                           n,\n",
    "                           model_name = IM_MODEL_NAME,\n",
    "                           learning_rate = IM_LEARNING_RATE,\n",
    "                           batch_size = IM_BATCH_SIZE,\n",
    "                           epochs = IM_EPOCHS,\n",
    "                           patience = IM_PATIENCE):\n",
    "\n",
    "    \"\"\"\n",
    "    Set up an run a DistilBert model on our TensorFlow training dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    # set up model\n",
    "    model = TFDistilBertForSequenceClassification.from_pretrained(model_name, num_labels = n)\n",
    "\n",
    "    # define loss function\n",
    "    loss = losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "    # define optimizer to be used to minimise loss\n",
    "    optimizer = optimizers.Adam(learning_rate)\n",
    "\n",
    "    # compile model\n",
    "    model.compile(optimizer = optimizer,\n",
    "                  loss = loss,\n",
    "                  metrics = \"accuracy\")\n",
    "\n",
    "    # fit model\n",
    "    model.fit(tfdataset_train,\n",
    "              batch_size = batch_size,\n",
    "              epochs = epochs,\n",
    "              validation_data = tfdataset_val,\n",
    "              callbacks = EarlyStopping(patience = patience, restore_best_weights = True))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e1bfeecd-221d-49ec-9ae5-be24749db71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ideology_model_predictor(model,\n",
    "                             tokens):\n",
    "    \"\"\"\n",
    "    This function uses the model output from the ideology_model function to output the\n",
    "    probabilities of each individual article being left or right wing (0 = left wing,\n",
    "    1 = right wing). As the model spits out log odds rather than probabilities, these\n",
    "    also need to be converted in this function into probabilities.\n",
    "    \"\"\"\n",
    "\n",
    "    # firstly create a TensorFlow version of our tokenized dataset without our y\n",
    "    tfdataset_no_y = tf.data.Dataset.from_tensor_slices(dict(tokens))\n",
    "\n",
    "    # use this to get out the logits for our model\n",
    "    pred_logits = model.predict(tfdataset_no_y)[0]\n",
    "\n",
    "    # convert these into probabilties\n",
    "    pred_probas = tf.nn.softmax(pred_logits).numpy()\n",
    "\n",
    "    return pred_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "941ee4bd-5a5e-45a1-ad3e-80ccf03940d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_class(pred_probas):\n",
    "\n",
    "    top_class_list = []\n",
    "\n",
    "    for row in range(len(pred_probas)):\n",
    "\n",
    "        conversion_dict = {0 : \"left\",\n",
    "                       1 : \"leans left\",\n",
    "                       2 : \"centre\",\n",
    "                       3 : \"leans right\",\n",
    "                       4 : \"right\"}\n",
    "\n",
    "        top_class_list.append(conversion_dict[np.argmax(pred_probas[row])])\n",
    "\n",
    "    return top_class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3d98c11f-14dd-4302-98ff-3600fd45311e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_n_class_ideology_model(df, n):\n",
    "\n",
    "    df = bias_score_encoding(df, n)\n",
    "\n",
    "    X, y = n_class_get_X_and_y(df)\n",
    "\n",
    "    tokenizer = instantiate_tokenizer(model_name = IM_MODEL_NAME)\n",
    "\n",
    "    tokens = text_tokenizer(X,\n",
    "                            tokenizer,\n",
    "                            max_len = IM_TOKEN_MAX_LEN,\n",
    "                            truncation = True,\n",
    "                            padding = \"max_length\")\n",
    "\n",
    "    tfdataset = tf_dataset_constructor(tokens, y)\n",
    "\n",
    "    # the following function automatically returns the test dataset, even though this is\n",
    "    # not used further, as we do not evaluate the model accuracy within this function.\n",
    "\n",
    "    tfdataset_train, tfdataset_val, tfdataset_test =\\\n",
    "    train_test_split(X,\n",
    "                    tfdataset,\n",
    "                    test_split = IM_TEST_SPLIT,\n",
    "                    val_split = IM_VALIDATION_SPLIT,\n",
    "                    batch_size = IM_BATCH_SIZE)\n",
    "\n",
    "    model = n_class_ideology_model(tfdataset_train,\n",
    "                           tfdataset_val,\n",
    "                           n,\n",
    "                           model_name = IM_MODEL_NAME,\n",
    "                           learning_rate = IM_LEARNING_RATE,\n",
    "                           batch_size = IM_BATCH_SIZE,\n",
    "                           epochs = IM_EPOCHS,\n",
    "                           patience = IM_PATIENCE)\n",
    "\n",
    "    pred_probas = ideology_model_predictor(model, tokens)\n",
    "\n",
    "    top_class_list = top_class(pred_probas)\n",
    "\n",
    "    df['pred_class'] = top_class_list\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5eaf695b-7f0c-470e-b76f-54c73fc60916",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "20/20 [==============================] - 20s 599ms/step - loss: 0.6270 - accuracy: 0.1750 - val_loss: 0.5411 - val_accuracy: 0.2500\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 11s 547ms/step - loss: 0.5245 - accuracy: 0.2750 - val_loss: 0.4822 - val_accuracy: 0.4167\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 11s 545ms/step - loss: 0.5001 - accuracy: 0.2750 - val_loss: 0.4750 - val_accuracy: 0.3333\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 11s 543ms/step - loss: 0.4797 - accuracy: 0.4750 - val_loss: 0.4445 - val_accuracy: 0.9167\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 11s 547ms/step - loss: 0.4453 - accuracy: 0.7000 - val_loss: 0.3848 - val_accuracy: 1.0000\n",
      "50/50 [==============================] - 3s 53ms/step\n"
     ]
    }
   ],
   "source": [
    "output_df = full_n_class_ideology_model(df,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b25ef82a-f20b-4fe1-8124-1e787193b760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>pre_process_text</th>\n",
       "      <th>discrete_bias_score</th>\n",
       "      <th>5_step_classifier</th>\n",
       "      <th>one_hot_discrete</th>\n",
       "      <th>pred_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>0</td>\n",
       "      <td>a trump statue has caught on with china’s onli...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>leans left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219</th>\n",
       "      <td>1</td>\n",
       "      <td>sen  ben sasse on capitol hill in washington  ...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>[1, 0, 0, 0, 0]</td>\n",
       "      <td>centre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2347</th>\n",
       "      <td>1</td>\n",
       "      <td>rising domestic supply and great efficiency ga...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 0, 0, 1]</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2117</th>\n",
       "      <td>1</td>\n",
       "      <td>republican south dakota gov  kristi noem on sa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 1, 0, 0]</td>\n",
       "      <td>centre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2418</th>\n",
       "      <td>1</td>\n",
       "      <td>president biden’s  build back better  campaign...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 0, 0, 1]</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1955</th>\n",
       "      <td>1</td>\n",
       "      <td>happy anniversary  it s one year since america...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 1, 0, 0]</td>\n",
       "      <td>centre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>0</td>\n",
       "      <td>let our journalists help you make sense of the...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 1, 0]</td>\n",
       "      <td>leans right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>0</td>\n",
       "      <td>during the trump years  there was an excessive...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 1, 0, 0]</td>\n",
       "      <td>centre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2602</th>\n",
       "      <td>1</td>\n",
       "      <td>when it comes time to retire and enjoy those g...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 1, 0, 0]</td>\n",
       "      <td>centre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>0</td>\n",
       "      <td>crises have a way of sorting the good presiden...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 0, 0, 1]</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>0</td>\n",
       "      <td>lorie ladd gazes into the camera with glossy e...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 0, 0, 1]</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>0</td>\n",
       "      <td>purim  which falls this year on feb    ranks a...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 1, 0]</td>\n",
       "      <td>leans right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>0</td>\n",
       "      <td>fox news host tucker carlson met twitter s wra...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 0, 0, 1]</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2116</th>\n",
       "      <td>1</td>\n",
       "      <td>department of homeland security  dhs  secretar...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 1, 0, 0]</td>\n",
       "      <td>centre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>0</td>\n",
       "      <td>election experts and other critics of voter su...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>leans left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2514</th>\n",
       "      <td>1</td>\n",
       "      <td>there’s a growing call for firms that do busin...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 0, 0, 1]</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>0</td>\n",
       "      <td>the united states secret service agents assign...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>[1, 0, 0, 0, 0]</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>0</td>\n",
       "      <td>let our journalists help you make sense of the...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>[1, 0, 0, 0, 0]</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569</th>\n",
       "      <td>0</td>\n",
       "      <td>subscribe to the nation subscribe now for as l...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>leans left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>0</td>\n",
       "      <td>new cnn original series “stanley tucci  search...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>[1, 0, 0, 0, 0]</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2377</th>\n",
       "      <td>1</td>\n",
       "      <td>former treasury secretary lawrence summers war...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 0, 0, 1]</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>0</td>\n",
       "      <td>a blow by blow account of how mental health ex...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 1, 0]</td>\n",
       "      <td>leans right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>0</td>\n",
       "      <td>president joe biden is advocating for states t...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 0, 0, 1]</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1844</th>\n",
       "      <td>1</td>\n",
       "      <td>fox news reports from an unnamed senior u s  c...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 1, 0]</td>\n",
       "      <td>leans right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>0</td>\n",
       "      <td>few places on the planet are more at risk from...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 1, 0]</td>\n",
       "      <td>leans right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2609</th>\n",
       "      <td>1</td>\n",
       "      <td>the coronavirus outbreak means that everyone i...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>leans left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1888</th>\n",
       "      <td>1</td>\n",
       "      <td>nato secretary general jens stoltenberg told t...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>[1, 0, 0, 0, 0]</td>\n",
       "      <td>centre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>0</td>\n",
       "      <td>this is a rush transcript  copy may no...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 0, 0, 1]</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>0</td>\n",
       "      <td>as the winter’s deadly coronavirus surge desce...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 1, 0]</td>\n",
       "      <td>leans right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>1</td>\n",
       "      <td>several players reportedly took a knee during ...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>[1, 0, 0, 0, 0]</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>0</td>\n",
       "      <td>as colorado celebrates its annual  meatout day...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>[1, 0, 0, 0, 0]</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>0</td>\n",
       "      <td>let our journalists help you make sense of the...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 0, 0, 1]</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>0</td>\n",
       "      <td>the border is not in crisis  the current incre...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>leans left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2433</th>\n",
       "      <td>1</td>\n",
       "      <td>bloomberg     denis sverdlov  a former russia...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 1, 0, 0]</td>\n",
       "      <td>centre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>0</td>\n",
       "      <td>about the show  navigating the marketplace is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 1, 0, 0]</td>\n",
       "      <td>centre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>0</td>\n",
       "      <td>rep  chip roy  r tx  kicked off thursday’s hou...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>leans left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2530</th>\n",
       "      <td>1</td>\n",
       "      <td>democrats don t have to dwell on the fact that...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>leans left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>0</td>\n",
       "      <td>right wing talk show host glenn beck told view...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>[1, 0, 0, 0, 0]</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2058</th>\n",
       "      <td>1</td>\n",
       "      <td>republican texas sen  ted cruz told daily call...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 1, 0, 0]</td>\n",
       "      <td>centre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1846</th>\n",
       "      <td>1</td>\n",
       "      <td>mexican law enforcement officials arrested a b...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 1, 0]</td>\n",
       "      <td>leans right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2168</th>\n",
       "      <td>1</td>\n",
       "      <td>the vast majority of americans  including afri...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>leans left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>0</td>\n",
       "      <td>let our journalists help you make sense of the...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 1, 0]</td>\n",
       "      <td>leans right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2350</th>\n",
       "      <td>1</td>\n",
       "      <td>of crisis and bad policy  one year ago  i wrot...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 0, 0, 1]</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>0</td>\n",
       "      <td>in their first meeting as heads of state  pres...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>leans left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>0</td>\n",
       "      <td>next month before a joint session of congress ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 1, 0, 0]</td>\n",
       "      <td>centre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>0</td>\n",
       "      <td>washington  cnn  senate minority leader mitch ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 1, 0]</td>\n",
       "      <td>leans right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>0</td>\n",
       "      <td>same sex marriage advocates expressed concern ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 0, 0, 1]</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>0</td>\n",
       "      <td>for four weeks now  thousands of residents of ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 0, 0, 1]</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>0</td>\n",
       "      <td>cnn  former bolivian interim president jeanin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 1, 0, 0]</td>\n",
       "      <td>centre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>1</td>\n",
       "      <td>venezuelan socialist dictator nicolás maduro r...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 1, 0, 0]</td>\n",
       "      <td>centre</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      classifier                                   pre_process_text  \\\n",
       "245            0  a trump statue has caught on with china’s onli...   \n",
       "2219           1  sen  ben sasse on capitol hill in washington  ...   \n",
       "2347           1  rising domestic supply and great efficiency ga...   \n",
       "2117           1  republican south dakota gov  kristi noem on sa...   \n",
       "2418           1  president biden’s  build back better  campaign...   \n",
       "1955           1  happy anniversary  it s one year since america...   \n",
       "1196           0  let our journalists help you make sense of the...   \n",
       "393            0  during the trump years  there was an excessive...   \n",
       "2602           1  when it comes time to retire and enjoy those g...   \n",
       "272            0  crises have a way of sorting the good presiden...   \n",
       "243            0  lorie ladd gazes into the camera with glossy e...   \n",
       "259            0  purim  which falls this year on feb    ranks a...   \n",
       "400            0  fox news host tucker carlson met twitter s wra...   \n",
       "2116           1  department of homeland security  dhs  secretar...   \n",
       "776            0  election experts and other critics of voter su...   \n",
       "2514           1  there’s a growing call for firms that do busin...   \n",
       "742            0  the united states secret service agents assign...   \n",
       "1216           0  let our journalists help you make sense of the...   \n",
       "1569           0  subscribe to the nation subscribe now for as l...   \n",
       "458            0  new cnn original series “stanley tucci  search...   \n",
       "2377           1  former treasury secretary lawrence summers war...   \n",
       "266            0  a blow by blow account of how mental health ex...   \n",
       "326            0  president joe biden is advocating for states t...   \n",
       "1844           1  fox news reports from an unnamed senior u s  c...   \n",
       "854            0  few places on the planet are more at risk from...   \n",
       "2609           1  the coronavirus outbreak means that everyone i...   \n",
       "1888           1  nato secretary general jens stoltenberg told t...   \n",
       "262            0          this is a rush transcript  copy may no...   \n",
       "1063           0  as the winter’s deadly coronavirus surge desce...   \n",
       "1935           1  several players reportedly took a knee during ...   \n",
       "359            0  as colorado celebrates its annual  meatout day...   \n",
       "1060           0  let our journalists help you make sense of the...   \n",
       "1428           0  the border is not in crisis  the current incre...   \n",
       "2433           1   bloomberg     denis sverdlov  a former russia...   \n",
       "1462           0  about the show  navigating the marketplace is ...   \n",
       "492            0  rep  chip roy  r tx  kicked off thursday’s hou...   \n",
       "2530           1  democrats don t have to dwell on the fact that...   \n",
       "760            0  right wing talk show host glenn beck told view...   \n",
       "2058           1  republican texas sen  ted cruz told daily call...   \n",
       "1846           1  mexican law enforcement officials arrested a b...   \n",
       "2168           1  the vast majority of americans  including afri...   \n",
       "1067           0  let our journalists help you make sense of the...   \n",
       "2350           1  of crisis and bad policy  one year ago  i wrot...   \n",
       "544            0  in their first meeting as heads of state  pres...   \n",
       "830            0  next month before a joint session of congress ...   \n",
       "394            0  washington  cnn  senate minority leader mitch ...   \n",
       "233            0  same sex marriage advocates expressed concern ...   \n",
       "1470           0  for four weeks now  thousands of residents of ...   \n",
       "711            0   cnn  former bolivian interim president jeanin...   \n",
       "1797           1  venezuelan socialist dictator nicolás maduro r...   \n",
       "\n",
       "      discrete_bias_score  5_step_classifier one_hot_discrete   pred_class  \n",
       "245                    -1                 -1  [0, 1, 0, 0, 0]   leans left  \n",
       "2219                   -2                 -2  [1, 0, 0, 0, 0]       centre  \n",
       "2347                    2                  2  [0, 0, 0, 0, 1]        right  \n",
       "2117                    0                  0  [0, 0, 1, 0, 0]       centre  \n",
       "2418                    2                  2  [0, 0, 0, 0, 1]        right  \n",
       "1955                    0                  0  [0, 0, 1, 0, 0]       centre  \n",
       "1196                    1                  1  [0, 0, 0, 1, 0]  leans right  \n",
       "393                     0                  0  [0, 0, 1, 0, 0]       centre  \n",
       "2602                    0                  0  [0, 0, 1, 0, 0]       centre  \n",
       "272                     2                  2  [0, 0, 0, 0, 1]        right  \n",
       "243                     2                  2  [0, 0, 0, 0, 1]        right  \n",
       "259                     1                  1  [0, 0, 0, 1, 0]  leans right  \n",
       "400                     2                  2  [0, 0, 0, 0, 1]        right  \n",
       "2116                    0                  0  [0, 0, 1, 0, 0]       centre  \n",
       "776                    -1                 -1  [0, 1, 0, 0, 0]   leans left  \n",
       "2514                    2                  2  [0, 0, 0, 0, 1]        right  \n",
       "742                    -2                 -2  [1, 0, 0, 0, 0]         left  \n",
       "1216                   -2                 -2  [1, 0, 0, 0, 0]         left  \n",
       "1569                   -1                 -1  [0, 1, 0, 0, 0]   leans left  \n",
       "458                    -2                 -2  [1, 0, 0, 0, 0]         left  \n",
       "2377                    2                  2  [0, 0, 0, 0, 1]        right  \n",
       "266                     1                  1  [0, 0, 0, 1, 0]  leans right  \n",
       "326                     2                  2  [0, 0, 0, 0, 1]        right  \n",
       "1844                    1                  1  [0, 0, 0, 1, 0]  leans right  \n",
       "854                     1                  1  [0, 0, 0, 1, 0]  leans right  \n",
       "2609                   -1                 -1  [0, 1, 0, 0, 0]   leans left  \n",
       "1888                   -2                 -2  [1, 0, 0, 0, 0]       centre  \n",
       "262                     2                  2  [0, 0, 0, 0, 1]        right  \n",
       "1063                    1                  1  [0, 0, 0, 1, 0]  leans right  \n",
       "1935                   -2                 -2  [1, 0, 0, 0, 0]         left  \n",
       "359                    -2                 -2  [1, 0, 0, 0, 0]         left  \n",
       "1060                    2                  2  [0, 0, 0, 0, 1]        right  \n",
       "1428                   -1                 -1  [0, 1, 0, 0, 0]   leans left  \n",
       "2433                    0                  0  [0, 0, 1, 0, 0]       centre  \n",
       "1462                    0                  0  [0, 0, 1, 0, 0]       centre  \n",
       "492                    -1                 -1  [0, 1, 0, 0, 0]   leans left  \n",
       "2530                   -1                 -1  [0, 1, 0, 0, 0]   leans left  \n",
       "760                    -2                 -2  [1, 0, 0, 0, 0]         left  \n",
       "2058                    0                  0  [0, 0, 1, 0, 0]       centre  \n",
       "1846                    1                  1  [0, 0, 0, 1, 0]  leans right  \n",
       "2168                   -1                 -1  [0, 1, 0, 0, 0]   leans left  \n",
       "1067                    1                  1  [0, 0, 0, 1, 0]  leans right  \n",
       "2350                    2                  2  [0, 0, 0, 0, 1]        right  \n",
       "544                    -1                 -1  [0, 1, 0, 0, 0]   leans left  \n",
       "830                     0                  0  [0, 0, 1, 0, 0]       centre  \n",
       "394                     1                  1  [0, 0, 0, 1, 0]  leans right  \n",
       "233                     2                  2  [0, 0, 0, 0, 1]        right  \n",
       "1470                    2                  2  [0, 0, 0, 0, 1]        right  \n",
       "711                     0                  0  [0, 0, 1, 0, 0]       centre  \n",
       "1797                    0                  0  [0, 0, 1, 0, 0]       centre  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acff2b9-97ed-497d-a513-c5a3fd98b296",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06172cd2-256e-46ee-9e4d-3d0e9c1681de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45392cb-d8fe-4643-9abd-4732dd6db142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236416c1-2b86-4b8a-a1bd-ee55b5fa7115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbff7c9c-09f3-481e-b7ac-f26a03b81b91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "207cae1a-8dc6-40dd-a739-f5c848953043",
   "metadata": {},
   "source": [
    "## The below is a working model based on binary classification only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fc7a9e-4b1c-454a-bef4-5f39d800cc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "IM_MODEL_NAME = \"distilbert-base-uncased\"\n",
    "IM_BATCH_SIZE = 2\n",
    "IM_LEARNING_RATE = 3e-5\n",
    "IM_TOKEN_MAX_LEN = 50   ### currently set at 50 to speed up basic model training\n",
    "IM_TEST_SPLIT = 0.2\n",
    "IM_VALIDATION_SPLIT = 0.3   ### refers to split withing training data (not whole dataset)\n",
    "IM_EPOCHS = 5   ### currently set to 5 to speed up basic model training\n",
    "IM_PATIENCE = 2   ### currently set to 2 due to the low number of epochs (5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1719ab50-f56d-4f99-82f1-06b15d43dd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_and_y(df):\n",
    "    \"\"\"\n",
    "    Gets from our dataset: (i) the feature (i.e. X - the pre-processed text);\n",
    "    and (ii) the target (i.e. y - the ideology: left wing = 0 / right wing = 1).\n",
    "    These need to be converted into lists for use in our model.\n",
    "    \"\"\"\n",
    "\n",
    "    X = df[\"pre_process_text\"].tolist()\n",
    "    y = df[\"classifier\"].tolist()\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb293e6-ebdc-4a50-b2ad-7ff6cc55c436",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantiate_tokenizer(model_name = IM_MODEL_NAME):\n",
    "    \"\"\"\n",
    "    Define the tokenizer we want to use in our modelling.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77ea881-76ec-4910-b7d6-2141bdde68af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_tokenizer(X,\n",
    "                   tokenizer,\n",
    "                   max_len = IM_TOKEN_MAX_LEN,\n",
    "                   truncation = True,\n",
    "                   padding = \"max_length\"):\n",
    "    \"\"\"\n",
    "    Returns a dictionary of tokenized text with 2 keys: \"input_ids\" and \"attention_mask\".\n",
    "    These 2 keys are required for the input into the DistilBert model.\n",
    "    \"\"\"\n",
    "\n",
    "    tokens = tokenizer(X, max_length = max_len, truncation = truncation, padding = padding)\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17789585-6507-4452-a251-69c4c0bfd4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_dataset_constructor(tokens,\n",
    "                           y):\n",
    "    \"\"\"\n",
    "    Using the tokenized input from the text_tokenizer function,\n",
    "    returns TensorFlow objects for use in the DistilBert model.\n",
    "    \"\"\"\n",
    "\n",
    "    tfdataset = tf.data.Dataset.from_tensor_slices((dict(tokens),y))\n",
    "\n",
    "    return tfdataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d165d5f-d65f-47c7-b763-cc24f5ceb853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X,\n",
    "                     tfdataset,\n",
    "                     test_split = IM_TEST_SPLIT,\n",
    "                     val_split = IM_VALIDATION_SPLIT,\n",
    "                     batch_size = IM_BATCH_SIZE):\n",
    "    \"\"\"\n",
    "    This function splits the TensorFlow object created in the tf_dataset_constructor function\n",
    "    into train, valdiation and test sets.\n",
    "    \"\"\"\n",
    "\n",
    "    # get the sizes of the train and validation sets\n",
    "    train_size = int(len(X) * (1-test_split))\n",
    "    val_size = int(train_size * val_split)\n",
    "\n",
    "    # shuffle the full dataset\n",
    "    tfdataset = tfdataset.shuffle(len(X))\n",
    "\n",
    "    # from the full datset, get out the train, validation and test sets\n",
    "    tfdataset_train = tfdataset.take(train_size)\n",
    "    tfdataset_val = tfdataset.skip(train_size - val_size).take(val_size)\n",
    "    tfdataset_test = tfdataset.skip(train_size)\n",
    "\n",
    "    # batch the train, validation and test sets\n",
    "    tfdataset_train = tfdataset_train.batch(batch_size)\n",
    "    tfdataset_val = tfdataset_val.batch(batch_size)\n",
    "    tfdataset_test = tfdataset_test.batch(batch_size)\n",
    "\n",
    "    return tfdataset_train, tfdataset_val, tfdataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a621268-ded6-40bf-a2f2-5c0c5a6a9a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ideology_model(tfdataset_train,\n",
    "                   tfdataset_val,\n",
    "                   model_name = IM_MODEL_NAME,\n",
    "                   learning_rate = IM_LEARNING_RATE,\n",
    "                   batch_size = IM_BATCH_SIZE,\n",
    "                   epochs = IM_EPOCHS,\n",
    "                   patience = IM_PATIENCE):\n",
    "\n",
    "    \"\"\"\n",
    "    Set up an run a DistilBert model on our TensorFlow training dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    # set up model\n",
    "    model = TFDistilBertForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "    # define loss function\n",
    "    loss = losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    # define optimizer to be used to minimise loss\n",
    "    optimizer = optimizers.Adam(learning_rate)\n",
    "\n",
    "    # compile model\n",
    "    model.compile(optimizer = optimizer,\n",
    "                  loss = loss,\n",
    "                  metrics = \"accuracy\")\n",
    "\n",
    "    # fit model\n",
    "    model.fit(tfdataset_train,\n",
    "              batch_size = batch_size,\n",
    "              epochs = epochs,\n",
    "              validation_data = tfdataset_val,\n",
    "              callbacks = EarlyStopping(patience = patience, restore_best_weights = True))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a35442-194d-4128-b27b-153bc7651617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ideology_model_evaluator(model,\n",
    "                             tfdataset_test,\n",
    "                             batch_size = IM_BATCH_SIZE):\n",
    "    \"\"\"\n",
    "    Evaluate our model on the TensorFlow test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    benchmarks = model.evaluate(tfdataset_test, batch_size = batch_size, return_dict = True)\n",
    "    accuracy = benchmarks[\"accuracy\"]\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8eec605-65bf-41b0-869a-edd2ca01ad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ideology_model_predictor(model,\n",
    "                             tokens):\n",
    "    \"\"\"\n",
    "    This function uses the model output from the ideology_model function to output the\n",
    "    probabilities of each individual article being left or right wing (0 = left wing,\n",
    "    1 = right wing). As the model spits out log odds rather than probabilities, these\n",
    "    also need to be converted in this function into probabilities.\n",
    "    \"\"\"\n",
    "\n",
    "    # firstly create a TensorFlow version of our tokenized dataset without our y\n",
    "    tfdataset_no_y = tf.data.Dataset.from_tensor_slices(dict(tokens))\n",
    "\n",
    "    # use this to get out the logits for our model\n",
    "    pred_logits = model.predict(tfdataset_no_y)[0]\n",
    "\n",
    "    # convert these into probabilties\n",
    "    pred_probas = tf.nn.softmax(pred_logits).numpy()\n",
    "\n",
    "    return pred_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbbf2c9-32fb-4de5-a158-13a35e8163e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_ideology_model(df):\n",
    "    \"\"\"\n",
    "    Combine all above functions into one master function, except for the\n",
    "    ideology_model_evaluator function, as we do not need the accuracy output here.\n",
    "    \"\"\"\n",
    "\n",
    "    X, y = get_X_and_y(df)\n",
    "\n",
    "    tokenizer = instantiate_tokenizer(model_name = IM_MODEL_NAME)\n",
    "\n",
    "    tokens = text_tokenizer(X,\n",
    "                            tokenizer,\n",
    "                            max_len = IM_TOKEN_MAX_LEN,\n",
    "                            truncation = True,\n",
    "                            padding = \"max_length\")\n",
    "\n",
    "    tfdataset = tf_dataset_constructor(tokens, y)\n",
    "\n",
    "    # the following function automatically returns the test dataset, even though this is\n",
    "    # not used further, as we do not evaluate the model accuracy within this function.\n",
    "\n",
    "    tfdataset_train, tfdataset_val, tfdataset_test =\\\n",
    "    train_test_split(X,\n",
    "                    tfdataset,\n",
    "                    test_split = IM_TEST_SPLIT,\n",
    "                    val_split = IM_VALIDATION_SPLIT,\n",
    "                    batch_size = IM_BATCH_SIZE)\n",
    "\n",
    "    model = ideology_model(tfdataset_train,\n",
    "                           tfdataset_val,\n",
    "                           model_name = IM_MODEL_NAME,\n",
    "                           learning_rate = IM_LEARNING_RATE,\n",
    "                           batch_size = IM_BATCH_SIZE,\n",
    "                           epochs = IM_EPOCHS,\n",
    "                           patience = IM_PATIENCE)\n",
    "\n",
    "\n",
    "    pred_probas = ideology_model_predictor(model, tokens)\n",
    "\n",
    "    # from the predicted probabilities, we want the second column, which shows the probability\n",
    "    # of the article being right-wing - a score near to 1 is very right wing; a score near to 0\n",
    "    # is very left wing. We then add this column onto our df and return the full df.\n",
    "\n",
    "    df['pred_probas'] = pred_probas[:,1]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fe6856-22a6-44bf-a92a-36c83670c2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = full_ideology_model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13c2803-dfdc-4c7e-a658-dfa60ae4e8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cf6326-c597-4d4a-87f2-1b6969baf22c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
