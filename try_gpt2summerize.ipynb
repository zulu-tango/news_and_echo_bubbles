{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47b154e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from urllib.parse import urlparse\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d90d3e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "brainded_left = pd.read_csv('braindedleft.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39419fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "brainded_right = pd.read_csv('braindedright.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "953ea83c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>link</th>\n",
       "      <th>pdate</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>keywords</th>\n",
       "      <th>tags</th>\n",
       "      <th>compound</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://www.infowars.com/posts/emergency-satur...</td>\n",
       "      <td>2021-03-20 17:59:17</td>\n",
       "      <td>Emergency Saturday Report! Great Reset Goes Of...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Have an important tip? Let us know. Email us h...</td>\n",
       "      <td>['report', 'rails', 'tech', 'waking', 'humanit...</td>\n",
       "      <td>set()</td>\n",
       "      <td>0.1759</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.117312</td>\n",
       "      <td>0.424270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://www.infowars.com/posts/researchers-bel...</td>\n",
       "      <td>2021-03-20 06:13:08</td>\n",
       "      <td>Researchers Believe It’s Possible To Become Im...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Have an important tip? Let us know. Email us h...</td>\n",
       "      <td>['paper', 'possible', 'ai', 'immortality', 'te...</td>\n",
       "      <td>set()</td>\n",
       "      <td>-0.4982</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.114192</td>\n",
       "      <td>0.463387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://www.infowars.com/posts/why-are-liberal...</td>\n",
       "      <td>2021-03-21 12:28:26</td>\n",
       "      <td>Why Are Liberals So Damn Stupid?</td>\n",
       "      <td>[]</td>\n",
       "      <td>Have an important tip? Let us know. Email us h...</td>\n",
       "      <td>['purge', 'sam', 'sensethe', 'tip', 'street', ...</td>\n",
       "      <td>set()</td>\n",
       "      <td>-0.7574</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.607143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>https://www.infowars.com/posts/elite-keeping-b...</td>\n",
       "      <td>2021-03-19 10:49:37</td>\n",
       "      <td>Elite Keeping Border Open to Justify More Covi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>In multiple articles I have published recently...</td>\n",
       "      <td>['elite', 'justify', 'lockdowns', 'borders', '...</td>\n",
       "      <td>set()</td>\n",
       "      <td>-0.9345</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.067909</td>\n",
       "      <td>0.440083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://www.infowars.com/posts/the-never-endin...</td>\n",
       "      <td>2021-03-18 08:29:03</td>\n",
       "      <td>The Never-Ending Battle For Liberty</td>\n",
       "      <td>[]</td>\n",
       "      <td>Have an important tip? Let us know. Email us h...</td>\n",
       "      <td>['political', 'american', 'power', 'john', 'st...</td>\n",
       "      <td>set()</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.084508</td>\n",
       "      <td>0.410792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               link  \\\n",
       "0           0  https://www.infowars.com/posts/emergency-satur...   \n",
       "1           1  https://www.infowars.com/posts/researchers-bel...   \n",
       "2           2  https://www.infowars.com/posts/why-are-liberal...   \n",
       "3           3  https://www.infowars.com/posts/elite-keeping-b...   \n",
       "4           4  https://www.infowars.com/posts/the-never-endin...   \n",
       "\n",
       "                 pdate                                              title  \\\n",
       "0  2021-03-20 17:59:17  Emergency Saturday Report! Great Reset Goes Of...   \n",
       "1  2021-03-20 06:13:08  Researchers Believe It’s Possible To Become Im...   \n",
       "2  2021-03-21 12:28:26                   Why Are Liberals So Damn Stupid?   \n",
       "3  2021-03-19 10:49:37  Elite Keeping Border Open to Justify More Covi...   \n",
       "4  2021-03-18 08:29:03                The Never-Ending Battle For Liberty   \n",
       "\n",
       "  author                                               text  \\\n",
       "0     []  Have an important tip? Let us know. Email us h...   \n",
       "1     []  Have an important tip? Let us know. Email us h...   \n",
       "2     []  Have an important tip? Let us know. Email us h...   \n",
       "3     []  In multiple articles I have published recently...   \n",
       "4     []  Have an important tip? Let us know. Email us h...   \n",
       "\n",
       "                                            keywords   tags  compound    neg  \\\n",
       "0  ['report', 'rails', 'tech', 'waking', 'humanit...  set()    0.1759  0.093   \n",
       "1  ['paper', 'possible', 'ai', 'immortality', 'te...  set()   -0.4982  0.073   \n",
       "2  ['purge', 'sam', 'sensethe', 'tip', 'street', ...  set()   -0.7574  0.140   \n",
       "3  ['elite', 'justify', 'lockdowns', 'borders', '...  set()   -0.9345  0.091   \n",
       "4  ['political', 'american', 'power', 'john', 'st...  set()    0.9995  0.088   \n",
       "\n",
       "     neu    pos  polarity  subjectivity  \n",
       "0  0.807  0.100  0.117312      0.424270  \n",
       "1  0.866  0.061  0.114192      0.463387  \n",
       "2  0.811  0.049  0.050000      0.607143  \n",
       "3  0.819  0.090  0.067909      0.440083  \n",
       "4  0.760  0.152  0.084508      0.410792  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brainded_right.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4112f9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#brainded_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5aae4005",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b177130",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c497b528",
   "metadata": {},
   "outputs": [],
   "source": [
    "testt11 = brainded_right[\"text\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ffeb67a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_ids = tokenizer.encode(testt11, return_tensors='pt')\n",
    "#input_ids\n",
    "#summary_ids = model.generate(input_ids, max_length=50, num_return_sequences=1, early_stopping=True)\n",
    "#summary_ids\n",
    "#summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "#testt11\n",
    "#summary\n",
    "#summary == testt11\n",
    "#len(summary)\n",
    "#len(testt11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5226ceae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "244625bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/renato/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/renato/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/renato/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def clean_text(text):\n",
    "    # Conversion en minuscules\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Suppression de la ponctuation et des caractères spéciaux\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Tokenisation des mots\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Suppression des mots vides (stop words)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Rejoindre les tokens pour former le texte nettoyé\n",
    "    cleaned_text = ' '.join(tokens)\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9aac8ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "texte11_clean = clean_text(testt11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f6efb27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(texte11_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fe86ef59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2252"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bc271be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'important tip let us know email us might future humans resurrect dead well russian researchers alexey turchin maxim chernyakov belong transhumanism movement wrote paper explaining roadmap immortality involves superintelligent ai systems powered dyson spheres primary technology might someday make resurrection possible turchin chernyakov wrote evidence afterlife theres also proof medical death end subjective experience death irreversible immortality impossible paper popular mechanics first reported titled classification approaches technological resurrection offers roadmap immortality alex jones breaks un setting medical tyranny policy gets around checks balances representative government enforcing people death seems permanent event actual proof irreversibility authors write method currently possible manymay become feasible future technological development turchin chernyakov examine conventional future technologies making humanity immortal cryogenics uploading brains onto cloud transplanted clone bodies said strong ai critical technology download brains contents technology could years away development ai going rather fast still far away able download human computer turchin told russia beyond want good probability success count year 2600 sure authors said power supply behind ai would powerful would need dyson spheres megastructure solar panels encompasses star captures large percentage power output paper describes life continued stream subjective experiences death end stream immortality researchers life stream without end resurrection continuation stream experiences arbitrarily long gap digital immortality inevitable'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texte11_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "208347c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer.encode(texte11_clean, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "38f066a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/renato/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:399: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "/Users/renato/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 248, but `max_length` is set to 150. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "summary_ids = model.generate(input_ids, max_length=150, num_return_sequences=1, early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b383fc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "749dfb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(testt11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ad8215d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "62938344",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(texte11_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59922d11",
   "metadata": {},
   "source": [
    "#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7fa5ac9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e168a875",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"text-generation\", model=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d53b5897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'important tip let us know email us might future humans resurrect dead well russian researchers alexey turchin maxim chernyakov belong transhumanism movement wrote paper explaining roadmap immortality involves superintelligent ai systems powered dyson spheres primary technology might someday make resurrection possible turchin chernyakov wrote evidence afterlife theres also proof medical death end subjective experience death irreversible immortality impossible paper popular mechanics first reported titled classification approaches technological resurrection offers roadmap immortality alex jones breaks un setting medical tyranny policy gets around checks balances representative government enforcing people death seems permanent event actual proof irreversibility authors write method currently possible manymay become feasible future technological development turchin chernyakov examine conventional future technologies making humanity immortal cryogenics uploading brains onto cloud transplanted clone bodies said strong ai critical technology download brains contents technology could years away development ai going rather fast still far away able download human computer turchin told russia beyond want good probability success count year 2600 sure authors said power supply behind ai would powerful would need dyson spheres megastructure solar panels encompasses star captures large percentage power output paper describes life continued stream subjective experiences death end stream immortality researchers life stream without end resurrection continuation stream experiences arbitrarily long gap digital immortality inevitable'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texte11_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8a2ad26f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "The model 'GPT2LMHeadModel' is not supported for summarization. Supported models are ['BartForConditionalGeneration', 'BigBirdPegasusForConditionalGeneration', 'BlenderbotForConditionalGeneration', 'BlenderbotSmallForConditionalGeneration', 'EncoderDecoderModel', 'FSMTForConditionalGeneration', 'GPTSanJapaneseForConditionalGeneration', 'LEDForConditionalGeneration', 'LongT5ForConditionalGeneration', 'M2M100ForConditionalGeneration', 'MarianMTModel', 'MBartForConditionalGeneration', 'MT5ForConditionalGeneration', 'MvpForConditionalGeneration', 'NllbMoeForConditionalGeneration', 'PegasusForConditionalGeneration', 'PegasusXForConditionalGeneration', 'PLBartForConditionalGeneration', 'ProphetNetForConditionalGeneration', 'SwitchTransformersForConditionalGeneration', 'T5ForConditionalGeneration', 'UMT5ForConditionalGeneration', 'XLMProphetNetForConditionalGeneration'].\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "sumgpt = pipeline(\"summarization\", model=\"gavin124/gpt2-finetuned-cnn-summarization-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dadb1c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1640"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texte11_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "09408159",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1647"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sumgpt(texte11_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "904703d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "69840054",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids2 = tokenizer.encode(texte11_clean, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "39ac22a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "/Users/renato/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 248, but `max_length` is set to 10. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "summary_ids2 = model.generate(input_ids2, max_length=10, num_return_sequences=1, early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "68cfcf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary2 = tokenizer.decode(summary_ids2[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b1348553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'important tip let us know email us might future humans resurrect dead well russian researchers alexey turchin maxim chernyakov belong transhumanism movement wrote paper explaining roadmap immortality involves superintelligent ai systems powered dyson spheres primary technology might someday make resurrection possible turchin chernyakov wrote evidence afterlife theres also proof medical death end subjective experience death irreversible immortality impossible paper popular mechanics first reported titled classification approaches technological resurrection offers roadmap immortality alex jones breaks un setting medical tyranny policy gets around checks balances representative government enforcing people death seems permanent event actual proof irreversibility authors write method currently possible manymay become feasible future technological development turchin chernyakov examine conventional future technologies making humanity immortal cryogenics uploading brains onto cloud transplanted clone bodies said strong ai critical technology download brains contents technology could years away development ai going rather fast still far away able download human computer turchin told russia beyond want good probability success count year 2600 sure authors said power supply behind ai would powerful would need dyson spheres megastructure solar panels encompasses star captures large percentage power output paper describes life continued stream subjective experiences death end stream immortality researchers life stream without end resurrection continuation stream experiences arbitrarily long gap digital immortality inevitable future'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8f6cda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
